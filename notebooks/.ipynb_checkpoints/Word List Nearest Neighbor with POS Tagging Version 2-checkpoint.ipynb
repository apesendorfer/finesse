{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "# cosine similarity of word vectors\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fasttext model\n",
    "\n",
    "model = fasttext.load_model(\"/Users/alex/result/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array to store word vectors\n",
    "\n",
    "#currently set to store 29153 words as their 100 dimensional word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(29153, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of words from combined TF-IDF analysis results\n",
    "\n",
    "f = open(\"word_list.txt\", \"r\")\n",
    "\n",
    "doc = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "#print(doc)\n",
    "\n",
    "words = doc.split(\", \")\n",
    "\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29153\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store word vectors for the 29153 words in numpy array\n",
    "\n",
    "for i in range(0, 29153):\n",
    "    arr[i] = model.get_word_vector(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# user word\n",
    "user_word = \"resolution\"\n",
    "\n",
    "user_word_vec = model.get_word_vector(user_word)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# iterate through numpy array and find vectors that meet a threshold for cosine similarity\n",
    "cos_sim = 0.4\n",
    "for i in range(0, 29153):\n",
    "    current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n",
    "    if current > cos_sim and words[i] != user_word and user_word[0:2] != words[i][0:2] and user_word[0:3] not in words[i]:\n",
    "        results[words[i]] = current\n",
    "        \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "# dictionary: results\n",
    "sorted_values = sorted(results.values(), reverse = True) # Sort the values\n",
    "sorted_dict = {}\n",
    "\n",
    "for i in sorted_values:\n",
    "    for k in results.keys():\n",
    "        if results[k] == i:\n",
    "            sorted_dict[k] = results[k]\n",
    "            break\n",
    "\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# user word\n",
    "user_words = [\"slowly\", \"carelessly\", \"accidentally\", \"staunchly\", \"thoroughly\", \"happily\"]\n",
    "\n",
    "for user_word in user_words:\n",
    "    user_word_vec = model.get_word_vector(user_word)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # iterate through numpy array and find vectors that meet a threshold for cosine similarity\n",
    "    cos_sim = 0.5\n",
    "    for i in range(0, 29153):\n",
    "        current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n",
    "        if current > cos_sim and words[i] != user_word and user_word[0:2] != words[i][0:2] and user_word[0:3] not in words[i]:\n",
    "            results[words[i]] = current\n",
    "    print(\"----------\")\n",
    "    print(user_word)\n",
    "    \n",
    "    # dictionary: results\n",
    "    sorted_values = sorted(results.values(), reverse = True) # Sort the values\n",
    "    sorted_dict = {}\n",
    "    for i in sorted_values:\n",
    "        for k in results.keys():\n",
    "            if results[k] == i:\n",
    "                sorted_dict[k] = results[k]\n",
    "                break\n",
    "\n",
    "    print(sorted_dict)\n",
    "    #print(results)\n",
    "    print(\"----------\")\n",
    "    #print(model.get_nearest_neighbors(user_word)[0:10])\n",
    "        \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts included in word list\n",
    "\n",
    "# gatsby, moby-dick, kerouac, gbg, invman, frankenstein\n",
    "\n",
    "txt1 = \"gatsby.txt\"\n",
    "txt2 = \"moby-dick.txt\"\n",
    "txt3 = \"kerouac.txt\"\n",
    "txt4 = \"gbg.txt\"\n",
    "txt5 = \"invman.txt\"\n",
    "txt6 = \"frankenstein.txt\"\n",
    "\n",
    "lst1 = [txt1, txt2, txt3, txt4, txt5, txt6]\n",
    "\n",
    "def concatenate(lst):\n",
    "    s = \"\"\n",
    "    for text in lst:\n",
    "        f = open(text, \"r\")\n",
    "        temp = f.read()\n",
    "        f.close()\n",
    "        s = s + temp\n",
    "    return s\n",
    "\n",
    "s = concatenate(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5085316"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:100]\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(s)\n",
    "\n",
    "#parser = CoreNLPParser(url='http://localhost:9000')\n",
    "#text = list(parser.tokenize(s[0:5075300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081628"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roadhouse', 'next', 'door', '.', 'And', 'then', 'came', 'that', 'disconcerting', 'ride', '.', 'We', 'hadn', '’', 't']\n"
     ]
    }
   ],
   "source": [
    "print(text[21030:21045])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%2Cpos%22%2C+%22ssplit.isOneSentence%22%3A+%22true%22%7D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-165988ee4e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_tagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoreNLPParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://localhost:9000'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21050\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21030\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m21045\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#text = nltk.word_tokenize(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    363\u001b[0m         ('unladen', 'JJ'), ('swallow', 'VB'), ('?', '.')]\n\u001b[1;32m    364\u001b[0m         \"\"\"\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_tag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mtag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# Converting list(list(str)) -> list(str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_tag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# Converting list(list(str)) -> list(str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_tag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mraw_tag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mdefault_properties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotators\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             yield [\n\u001b[1;32m    388\u001b[0m                 [\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, data, properties, timeout)\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%2Cpos%22%2C+%22ssplit.isOneSentence%22%3A+%22true%22%7D"
     ]
    }
   ],
   "source": [
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "l = list(pos_tagger.tag(text[21050:]))\n",
    "print(text[21030:21045])\n",
    "\n",
    "#text = nltk.word_tokenize(s)\n",
    "#l = list(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\ufeffThe', 'NN'), ('Project', 'NNP'), ('Gutenberg', 'NNP'), ('eBook', 'NN'), ('of', 'IN'), ('The', 'DT'), ('Great', 'NNP'), ('Gatsby', 'NNP'), (',', ','), ('by', 'IN'), ('F.', 'NNP'), ('Scott', 'NNP'), ('Fitzgerald', 'NNP'), ('This', 'DT'), ('eBook', 'NN'), ('is', 'VBZ'), ('for', 'IN'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('anyone', 'NN'), ('anywhere', 'RB'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('and', 'CC'), ('most', 'JJS'), ('other', 'JJ'), ('parts', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('world', 'NN'), ('at', 'IN'), ('no', 'DT'), ('cost', 'NN'), ('and', 'CC'), ('with', 'IN'), ('almost', 'RB'), ('no', 'DT'), ('restrictions', 'NNS'), ('whatsoever', 'RB'), ('.', '.'), ('You', 'PRP'), ('may', 'MD'), ('copy', 'VB'), ('it', 'PRP'), (',', ','), ('give', 'VB'), ('it', 'PRP'), ('away', 'RB'), ('or', 'CC'), ('re-use', 'VB'), ('it', 'PRP'), ('under', 'IN'), ('the', 'DT'), ('terms', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Project', 'NNP'), ('Gutenberg', 'NNP'), ('License', 'NNP'), ('included', 'VBD'), ('with', 'IN'), ('this', 'DT'), ('eBook', 'NN'), ('or', 'CC'), ('online', 'NN'), ('at', 'IN'), ('www.gutenberg.org', 'NN'), ('.', '.'), ('If', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('not', 'RB'), ('located', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), (',', ','), ('you', 'PRP'), ('will', 'MD'), ('have', 'VB'), ('to', 'TO'), ('check', 'VB'), ('the', 'DT'), ('laws', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('country', 'NN'), ('where', 'WRB'), ('you', 'PRP'), ('are', 'VBP'), ('located', 'VBN'), ('before', 'IN'), ('using', 'VBG'), ('this', 'DT'), ('eBook', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(l[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081628\n"
     ]
    }
   ],
   "source": [
    "lst1 = set(words)\n",
    "\n",
    "print(len(l))\n",
    "\n",
    "lst2 = []\n",
    "for i in range(len(l)):\n",
    "    lst2.append(l[i][0])\n",
    "lst2 = set(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29153\n",
      "44359\n"
     ]
    }
   ],
   "source": [
    "print(len(lst1))\n",
    "print(len(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate the intersection\n",
    "# of two lists using set() method\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "lst3 = intersection(lst1, lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25209"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [word for word in lst1 if word not in lst3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cxv', 'hotrods', 'greenville', 'trousered', 'bullied', 'dublin', 'agora', 'japhies', 'scupper', 'jitney']\n"
     ]
    }
   ],
   "source": [
    "print(a[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ahem', 'barbarization', 'leading', 'lulls', 'taunt', 'tiniest', 'underived', 'pleadin', 'pewter', 'horrors']\n",
      "25209\n"
     ]
    }
   ],
   "source": [
    "# THE WORD LIST THAT WILL BE USED IS NOW lst3\n",
    "\n",
    "print(lst3[0:10])\n",
    "print(len(lst3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keys = []\n",
    "pos_values = []\n",
    "for i in range(len(l)):\n",
    "    pos_keys.append(l[i][0])\n",
    "    pos_values.append(l[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Great', 'Gatsby', ',', 'by']\n",
      "['NN', 'NNP', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NNP', ',', 'IN']\n"
     ]
    }
   ],
   "source": [
    "print(pos_keys[0:10])\n",
    "print(pos_values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(len(pos_keys)):\n",
    "    if pos_keys[i] not in d:\n",
    "        d[pos_keys[i]] = [pos_values[i]]\n",
    "    else:\n",
    "        if pos_values[i] not in d[pos_keys[i]]:\n",
    "            d[pos_keys[i]].append(pos_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\ufeffThe': ['NN', \"''\"],\n",
       " 'Project': ['NNP', 'NN', 'JJ', 'VB'],\n",
       " 'Gutenberg': ['NNP'],\n",
       " 'eBook': ['NN', 'VBD'],\n",
       " 'of': ['IN'],\n",
       " 'The': ['DT'],\n",
       " 'Great': ['NNP', 'JJ', 'NN'],\n",
       " 'Gatsby': ['NNP', 'VBZ'],\n",
       " ',': [','],\n",
       " 'by': ['IN'],\n",
       " 'F.': ['NNP'],\n",
       " 'Scott': ['NNP'],\n",
       " 'Fitzgerald': ['NNP'],\n",
       " 'This': ['DT'],\n",
       " 'is': ['VBZ'],\n",
       " 'for': ['IN'],\n",
       " 'the': ['DT'],\n",
       " 'use': ['NN', 'VBP', 'VB', 'RB', 'IN'],\n",
       " 'anyone': ['NN'],\n",
       " 'anywhere': ['RB', 'JJ', 'VB'],\n",
       " 'in': ['IN'],\n",
       " 'United': ['NNP'],\n",
       " 'States': ['NNPS'],\n",
       " 'and': ['CC'],\n",
       " 'most': ['JJS', 'RBS', 'VBN', 'VB'],\n",
       " 'other': ['JJ'],\n",
       " 'parts': ['NNS'],\n",
       " 'world': ['NN'],\n",
       " 'at': ['IN'],\n",
       " 'no': ['DT', 'RB', 'VBD'],\n",
       " 'cost': ['NN', 'VB', 'VBN', 'VBD', 'VBP'],\n",
       " 'with': ['IN'],\n",
       " 'almost': ['RB'],\n",
       " 'restrictions': ['NNS'],\n",
       " 'whatsoever': ['RB', 'NN'],\n",
       " '.': ['.'],\n",
       " 'You': ['PRP'],\n",
       " 'may': ['MD'],\n",
       " 'copy': ['VB', 'NN'],\n",
       " 'it': ['PRP'],\n",
       " 'give': ['VB', 'VBP', 'JJ', 'NN'],\n",
       " 'away': ['RB', 'RP', 'JJ', 'NN'],\n",
       " 'or': ['CC'],\n",
       " 're-use': ['VB'],\n",
       " 'under': ['IN'],\n",
       " 'terms': ['NNS'],\n",
       " 'License': ['NNP'],\n",
       " 'included': ['VBD', 'VBN'],\n",
       " 'this': ['DT'],\n",
       " 'online': ['NN', 'JJ'],\n",
       " 'www.gutenberg.org': ['NN', 'JJ', '$'],\n",
       " 'If': ['IN'],\n",
       " 'you': ['PRP'],\n",
       " 'are': ['VBP'],\n",
       " 'not': ['RB'],\n",
       " 'located': ['VBN', 'VBD'],\n",
       " 'will': ['MD'],\n",
       " 'have': ['VB', 'VBP', 'JJ'],\n",
       " 'to': ['TO'],\n",
       " 'check': ['VB', 'NN'],\n",
       " 'laws': ['NNS'],\n",
       " 'country': ['NN'],\n",
       " 'where': ['WRB'],\n",
       " 'before': ['IN', 'RB', 'NN', 'VBP'],\n",
       " 'using': ['VBG'],\n",
       " 'Title': ['NN'],\n",
       " ':': [':'],\n",
       " 'Author': ['NNP', 'NN'],\n",
       " 'Release': ['NNP'],\n",
       " 'Date': ['NNP'],\n",
       " 'January': ['NNP'],\n",
       " '17': ['CD'],\n",
       " '2021': ['CD'],\n",
       " '[': ['NNP', 'NN', 'VB', '$', 'CC', 'VBZ', 'VBD', 'VBP', 'JJ'],\n",
       " '#': ['#'],\n",
       " '64317': ['CD'],\n",
       " ']': ['JJ', 'NN', 'NNP', 'IN', 'NNS', 'FW', 'VBN', 'VB', 'VBZ'],\n",
       " 'Most': ['NNP', 'JJS'],\n",
       " 'recently': ['RB'],\n",
       " 'updated': ['VBD'],\n",
       " '24': ['CD'],\n",
       " 'Language': ['NNP', 'VB', 'NN'],\n",
       " 'English': ['JJ', 'NNP', 'VB', 'NNPS'],\n",
       " 'Character': ['NNP'],\n",
       " 'set': ['VBD', 'VBN', 'NN', 'VB', 'VBP', 'JJ'],\n",
       " 'encoding': ['VBG'],\n",
       " 'UTF-8': ['NN'],\n",
       " 'Produced': ['VBN', 'NNP'],\n",
       " 'Alex': ['NNP'],\n",
       " 'Cabal': ['NNP'],\n",
       " 'Standard': ['NNP'],\n",
       " 'Ebooks': ['NNP'],\n",
       " 'project': ['NN', 'VB'],\n",
       " 'based': ['VBN'],\n",
       " 'on': ['IN'],\n",
       " 'a': ['DT'],\n",
       " 'transcription': ['NN'],\n",
       " 'produced': ['VBN', 'VBD', 'JJ'],\n",
       " 'Australia': ['NNP'],\n",
       " '*': ['VB', 'JJ', 'NNP', 'VBZ', 'NN', 'IN', 'CC', 'VBD', 'RB', 'VBP'],\n",
       " 'START': ['NNP', 'NN'],\n",
       " 'OF': ['IN', 'NNP'],\n",
       " 'THE': ['NNP', 'DT', 'NNPS'],\n",
       " 'PROJECT': ['NNP'],\n",
       " 'GUTENBERG': ['NNP'],\n",
       " 'EBOOK': ['NNP'],\n",
       " 'GREAT': ['NNP'],\n",
       " 'GATSBY': ['NNP'],\n",
       " 'Table': ['NNP'],\n",
       " 'Contents': ['NNP'],\n",
       " 'I': ['PRP'],\n",
       " 'II': ['NNP'],\n",
       " 'III': ['NNP', 'NN'],\n",
       " 'IV': ['NNP'],\n",
       " 'V': ['NNP'],\n",
       " 'VI': ['NNP', 'VB'],\n",
       " 'VII': ['NNP', 'VB'],\n",
       " 'VIII': ['NNP'],\n",
       " 'IX': ['NNP'],\n",
       " 'Once': ['RB', 'NNP', 'IN'],\n",
       " 'again': ['RB'],\n",
       " 'Zelda': ['NNP'],\n",
       " 'Then': ['RB'],\n",
       " 'wear': ['VBD', 'VB', 'VBP', 'IN', 'JJ'],\n",
       " 'gold': ['NN', 'JJ'],\n",
       " 'hat': ['NN', 'DT', 'RB', 'WP'],\n",
       " 'if': ['IN'],\n",
       " 'that': ['DT', 'IN', 'WDT', 'RB'],\n",
       " 'move': ['VB', 'NN', 'VBP'],\n",
       " 'her': ['PRP$', 'PRP', 'NN'],\n",
       " ';': [':'],\n",
       " 'can': ['MD'],\n",
       " 'bounce': ['VB', 'NN'],\n",
       " 'high': ['JJ', 'RB', 'VB', 'VBP', 'NN'],\n",
       " 'too': ['RB'],\n",
       " 'Till': ['NNP'],\n",
       " 'she': ['PRP'],\n",
       " 'cry': ['VBD', 'VB', 'NN', 'VBZ', 'VBP'],\n",
       " '“': ['NNP',\n",
       "  'VB',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'CC',\n",
       "  'FW',\n",
       "  'NNS',\n",
       "  'VBD',\n",
       "  'IN',\n",
       "  'VBZ',\n",
       "  'VBP',\n",
       "  'RB',\n",
       "  'PRP',\n",
       "  \"''\",\n",
       "  'RP',\n",
       "  'WDT',\n",
       "  'VBN',\n",
       "  'PDT',\n",
       "  'MD',\n",
       "  'RBR',\n",
       "  'EX',\n",
       "  'NNPS'],\n",
       " 'Lover': ['NNP'],\n",
       " 'gold-hatted': ['JJ'],\n",
       " 'high-bouncing': ['JJ'],\n",
       " 'lover': ['NN', 'VBZ', 'RB'],\n",
       " 'must': ['MD'],\n",
       " '!': ['.'],\n",
       " '”': ['VB',\n",
       "  'NN',\n",
       "  'NNP',\n",
       "  'CC',\n",
       "  'EX',\n",
       "  'IN',\n",
       "  'VBZ',\n",
       "  \"''\",\n",
       "  'JJ',\n",
       "  'FW',\n",
       "  'RB',\n",
       "  'UH',\n",
       "  'VBD',\n",
       "  'RP',\n",
       "  'VBP',\n",
       "  'NNS',\n",
       "  'PDT',\n",
       "  'PRP',\n",
       "  'CD',\n",
       "  'TO'],\n",
       " 'Thomas': ['NNP'],\n",
       " 'Parke': ['NNP'],\n",
       " 'd': ['NN', 'JJ', 'VB', 'NNS', 'RB', 'VBZ', 'VBD', 'VBP'],\n",
       " '’': ['NN',\n",
       "  'VBP',\n",
       "  'NNP',\n",
       "  'JJ',\n",
       "  'VBD',\n",
       "  'MD',\n",
       "  'VB',\n",
       "  'VBZ',\n",
       "  'FW',\n",
       "  'NNS',\n",
       "  'PRP',\n",
       "  'JJR',\n",
       "  'RB',\n",
       "  'CC',\n",
       "  'IN',\n",
       "  'EX',\n",
       "  'RBR',\n",
       "  'POS',\n",
       "  '$',\n",
       "  \"''\",\n",
       "  'UH'],\n",
       " 'Invilliers': ['NNP'],\n",
       " 'In': ['IN'],\n",
       " 'my': ['PRP$'],\n",
       " 'younger': ['JJR', 'RB', 'NN'],\n",
       " 'more': ['RBR', 'JJR'],\n",
       " 'vulnerable': ['JJ'],\n",
       " 'years': ['NNS'],\n",
       " 'father': ['NN', 'RB', 'JJ'],\n",
       " 'gave': ['VBD'],\n",
       " 'me': ['PRP'],\n",
       " 'some': ['DT'],\n",
       " 'advice': ['NN', 'RB'],\n",
       " 've': ['RB', 'JJ', 'NNS', 'VBG', 'NN', 'NNP', 'IN'],\n",
       " 'been': ['VBN'],\n",
       " 'turning': ['VBG', 'NN', 'JJ'],\n",
       " 'over': ['IN', 'RP', 'RB', 'VB', 'NN', 'VBN'],\n",
       " 'mind': ['NN', 'VB', 'IN', 'VBP'],\n",
       " 'ever': ['RB'],\n",
       " 'since': ['IN'],\n",
       " 'Whenever': ['NNP', 'WRB', 'IN'],\n",
       " 'feel': ['VBP', 'VB', 'NN', 'JJ'],\n",
       " 'like': ['IN', 'VB', 'VBP', 'JJ', 'NN'],\n",
       " 'criticizing': ['VBG'],\n",
       " 'he': ['PRP'],\n",
       " 'told': ['VBD', 'VBN', 'RB', 'NN', 'VB', 'JJ'],\n",
       " 'just': ['RB'],\n",
       " 'remember': ['VB', 'VBP', 'NN'],\n",
       " 'all': ['PDT', 'DT', 'RB', 'VB'],\n",
       " 'people': ['NNS'],\n",
       " 'haven': ['NN', 'VBP', 'RB', 'JJ'],\n",
       " 't': ['NN', 'NNS', 'VBD', 'VB', 'JJ', 'IN', 'VBZ', 'RB', 'VBP', 'CC', 'NNP'],\n",
       " 'had': ['VBD', 'VBN'],\n",
       " 'advantages': ['NNS', 'VBZ'],\n",
       " 'had.': ['NN', 'VBD'],\n",
       " 'He': ['PRP'],\n",
       " 'didn': ['VBZ', 'VBP', 'VBD', 'JJ', 'NN', 'VB'],\n",
       " 'say': ['VBP', 'VB', 'UH', 'NN'],\n",
       " 'any': ['DT'],\n",
       " 'but': ['CC'],\n",
       " 'we': ['PRP'],\n",
       " 'always': ['RB'],\n",
       " 'unusually': ['RB'],\n",
       " 'communicative': ['JJ'],\n",
       " 'reserved': ['JJ', 'VBD', 'VBN'],\n",
       " 'way': ['NN'],\n",
       " 'understood': ['VBP', 'VBD', 'JJ', 'NN', 'VBN', 'MD', 'RB'],\n",
       " 'meant': ['VBD', 'VBP', 'VB', 'VBN', 'NN', 'JJ'],\n",
       " 'great': ['JJ'],\n",
       " 'deal': ['NN', 'VB'],\n",
       " 'than': ['IN'],\n",
       " 'consequence': ['NN'],\n",
       " 'm': ['RB', 'NNS', 'JJ', 'VB', 'PDT', 'MD', 'NN'],\n",
       " 'inclined': ['VBN', 'JJ', 'VBD'],\n",
       " 'reserve': ['VB', 'NN'],\n",
       " 'judgements': ['NNS'],\n",
       " 'habit': ['NN', 'VB'],\n",
       " 'has': ['VBZ'],\n",
       " 'opened': ['VBN', 'VBD', 'JJ'],\n",
       " 'up': ['RP', 'RB', 'IN', 'JJ', 'NN'],\n",
       " 'many': ['JJ'],\n",
       " 'curious': ['JJ'],\n",
       " 'natures': ['NNS'],\n",
       " 'also': ['RB'],\n",
       " 'made': ['VBD', 'VBN', 'RBR', 'NN', 'VBP', 'VB'],\n",
       " 'victim': ['NN'],\n",
       " 'few': ['JJ'],\n",
       " 'veteran': ['NN', 'JJ'],\n",
       " 'bores': ['NNS'],\n",
       " 'abnormal': ['JJ'],\n",
       " 'quick': ['JJ', 'RB', 'NN', 'VBP', 'VB'],\n",
       " 'detect': ['VB', 'VBP'],\n",
       " 'attach': ['VB'],\n",
       " 'itself': ['PRP'],\n",
       " 'quality': ['NN'],\n",
       " 'when': ['WRB'],\n",
       " 'appears': ['VBZ'],\n",
       " 'normal': ['JJ'],\n",
       " 'person': ['NN'],\n",
       " 'so': ['RB', 'IN', 'CC', 'NNS', 'VB', 'VBP'],\n",
       " 'came': ['VBD'],\n",
       " 'about': ['IN', 'RB', 'RP'],\n",
       " 'college': ['NN'],\n",
       " 'was': ['VBD'],\n",
       " 'unjustly': ['RB'],\n",
       " 'accused': ['VBN', 'JJ', 'VBD'],\n",
       " 'being': ['VBG'],\n",
       " 'politician': ['NN'],\n",
       " 'because': ['IN', 'RB', 'VB'],\n",
       " 'privy': ['VBN', 'NN', 'JJ'],\n",
       " 'secret': ['JJ', 'NN', 'VBD'],\n",
       " 'griefs': ['NN', 'NNS', 'JJ'],\n",
       " 'wild': ['JJ', 'NN', 'VB', 'VBZ', 'VBP', 'RB'],\n",
       " 'unknown': ['JJ', 'NN'],\n",
       " 'men': ['NNS'],\n",
       " 'confidences': ['NNS'],\n",
       " 'were': ['VBD'],\n",
       " 'unsought—frequently': ['RB'],\n",
       " 'feigned': ['VBN', 'VBD'],\n",
       " 'sleep': ['NN', 'VB', 'JJ', 'VBP', 'RB', 'VBD'],\n",
       " 'preoccupation': ['NN'],\n",
       " 'hostile': ['JJ', 'NN'],\n",
       " 'levity': ['NN'],\n",
       " 'realized': ['VBN', 'VBD'],\n",
       " 'unmistakable': ['JJ'],\n",
       " 'sign': ['NN', 'VBZ', 'VB', 'VBP'],\n",
       " 'an': ['DT'],\n",
       " 'intimate': ['JJ', 'NN'],\n",
       " 'revelation': ['NN'],\n",
       " 'quivering': ['VBG', 'NN', 'JJ'],\n",
       " 'horizon': ['NN'],\n",
       " 'revelations': ['NNS'],\n",
       " 'young': ['JJ'],\n",
       " 'least': ['JJS', 'NN', 'RBS', 'JJ'],\n",
       " 'which': ['WDT'],\n",
       " 'they': ['PRP'],\n",
       " 'express': ['VBP', 'VB', 'JJ', 'NN', 'RB'],\n",
       " 'them': ['PRP'],\n",
       " 'usually': ['RB'],\n",
       " 'plagiaristic': ['JJ'],\n",
       " 'marred': ['VBN', 'VBD'],\n",
       " 'obvious': ['JJ'],\n",
       " 'suppressions': ['NNS'],\n",
       " 'Reserving': ['VBG'],\n",
       " 'matter': ['NN', 'VB'],\n",
       " 'infinite': ['JJ', 'NN'],\n",
       " 'hope': ['NN', 'VBP', 'VB', 'VBN'],\n",
       " 'am': ['VBP'],\n",
       " 'still': ['RB'],\n",
       " 'little': ['JJ', 'RB', 'VBP'],\n",
       " 'afraid': ['NN', 'VBN', 'JJ', 'VBD', 'IN', 'RB', 'VBP', 'RP', 'VB'],\n",
       " 'missing': ['VBG', 'JJ', 'NN'],\n",
       " 'something': ['NN'],\n",
       " 'forget': ['VBP', 'VB', 'NN', 'NNS', 'VBZ'],\n",
       " 'as': ['IN', 'RB'],\n",
       " 'snobbishly': ['RB'],\n",
       " 'suggested': ['VBN', 'VBD'],\n",
       " 'repeat': ['NN', 'VB', 'VBD', 'VBP'],\n",
       " 'sense': ['NN', 'VB'],\n",
       " 'fundamental': ['JJ'],\n",
       " 'decencies': ['NNS'],\n",
       " 'parcelled': ['VBN'],\n",
       " 'out': ['RP', 'IN', 'RB', 'NN'],\n",
       " 'unequally': ['RB'],\n",
       " 'birth': ['NN', 'JJ', 'VB'],\n",
       " 'And': ['CC'],\n",
       " 'after': ['IN'],\n",
       " 'boasting': ['VBG', 'NN'],\n",
       " 'tolerance': ['NN'],\n",
       " 'come': ['VBP', 'VBN', 'VB', 'NN', 'VBZ', 'VBD', 'JJ'],\n",
       " 'admission': ['NN'],\n",
       " 'limit': ['NN', 'VB'],\n",
       " 'Conduct': ['NN'],\n",
       " 'be': ['VB'],\n",
       " 'founded': ['VBN', 'VBD'],\n",
       " 'hard': ['JJ', 'RB', 'VB', 'NN'],\n",
       " 'rock': ['NN', 'VB', 'VBP'],\n",
       " 'wet': ['JJ', 'VBD', 'NN', 'VBP', 'IN', 'VB', 'NNS', 'VBN'],\n",
       " 'marshes': ['NNS'],\n",
       " 'certain': ['JJ'],\n",
       " 'point': ['NN', 'VB', 'JJ'],\n",
       " 'don': ['VBP', 'VB', 'NN', 'JJ', 'VBZ', 'CC'],\n",
       " 'care': ['NN', 'VBP', 'VB'],\n",
       " 'what': ['WP', 'WDT'],\n",
       " 's': ['PRP',\n",
       "  'NN',\n",
       "  'JJ',\n",
       "  'VBD',\n",
       "  'VB',\n",
       "  'VBP',\n",
       "  'VBZ',\n",
       "  'RB',\n",
       "  'PDT',\n",
       "  'JJR',\n",
       "  'POS',\n",
       "  'NNP',\n",
       "  'NNS',\n",
       "  'CC',\n",
       "  'FW',\n",
       "  'MD'],\n",
       " 'When': ['WRB'],\n",
       " 'back': ['RB', 'RP', 'NN', 'JJ', 'VBP', 'VB'],\n",
       " 'from': ['IN'],\n",
       " 'East': ['NNP'],\n",
       " 'last': ['JJ'],\n",
       " 'autumn': ['NN', 'JJ'],\n",
       " 'felt': ['VBD', 'RB', 'VBN', 'NN', 'VBP', 'JJ', 'NNS'],\n",
       " 'wanted': ['VBD', 'VBN'],\n",
       " 'uniform': ['JJ', 'NN'],\n",
       " 'sort': ['NN', 'VB'],\n",
       " 'moral': ['JJ', 'NN'],\n",
       " 'attention': ['NN'],\n",
       " 'forever': ['RB', 'NN', 'VBP'],\n",
       " 'riotous': ['JJ'],\n",
       " 'excursions': ['NNS'],\n",
       " 'privileged': ['JJ', 'VBN', 'NN'],\n",
       " 'glimpses': ['NNS'],\n",
       " 'into': ['IN'],\n",
       " 'human': ['JJ', 'NN', 'VBP'],\n",
       " 'heart': ['NN'],\n",
       " 'Only': ['RB', 'JJ'],\n",
       " 'man': ['NN'],\n",
       " 'who': ['WP'],\n",
       " 'gives': ['VBZ'],\n",
       " 'his': ['PRP$'],\n",
       " 'name': ['NN', 'VB', 'VBP'],\n",
       " 'book': ['NN'],\n",
       " 'exempt': ['JJ', 'VB'],\n",
       " 'reaction—Gatsby': ['NN'],\n",
       " 'represented': ['VBD', 'VBN'],\n",
       " 'everything': ['NN'],\n",
       " 'unaffected': ['JJ', 'VBN'],\n",
       " 'scorn': ['NN', 'NNS', 'VB', 'JJ'],\n",
       " 'personality': ['NN'],\n",
       " 'unbroken': ['JJ', 'VBN'],\n",
       " 'series': ['NN'],\n",
       " 'successful': ['JJ'],\n",
       " 'gestures': ['NNS', 'VBZ'],\n",
       " 'then': ['RB'],\n",
       " 'there': ['EX', 'RB', 'VB'],\n",
       " 'gorgeous': ['JJ'],\n",
       " 'him': ['PRP'],\n",
       " 'heightened': ['VBN', 'VBD', 'JJ'],\n",
       " 'sensitivity': ['NN'],\n",
       " 'promises': ['NNS', 'VBZ'],\n",
       " 'life': ['NN'],\n",
       " 'related': ['VBN', 'JJ', 'VBD'],\n",
       " 'one': ['CD', 'NN', 'PRP'],\n",
       " 'those': ['DT'],\n",
       " 'intricate': ['JJ'],\n",
       " 'machines': ['NNS'],\n",
       " 'register': ['NN'],\n",
       " 'earthquakes': ['NNS'],\n",
       " 'ten': ['VBP',\n",
       "  'RB',\n",
       "  'NNS',\n",
       "  'JJ',\n",
       "  'VB',\n",
       "  'NN',\n",
       "  'PRP',\n",
       "  'CD',\n",
       "  'VBN',\n",
       "  'VBZ',\n",
       "  'EX'],\n",
       " 'thousand': ['VBP', 'CD', 'NN', 'JJ', 'WDT', 'NNS'],\n",
       " 'miles': ['NNS'],\n",
       " 'responsiveness': ['NN'],\n",
       " 'nothing': ['NN'],\n",
       " 'do': ['VB', 'VBP', 'NN'],\n",
       " 'flabby': ['NN'],\n",
       " 'impressionability': ['NN'],\n",
       " 'dignified': ['VBN', 'JJ', 'VBD'],\n",
       " 'creative': ['JJ'],\n",
       " 'temperament': ['NN'],\n",
       " '—it': ['NNP', 'JJ', 'NN', 'CC'],\n",
       " 'extraordinary': ['JJ'],\n",
       " 'gift': ['NN'],\n",
       " 'romantic': ['JJ'],\n",
       " 'readiness': ['NN', 'JJ'],\n",
       " 'such': ['JJ', 'PDT', 'VB'],\n",
       " 'never': ['RB'],\n",
       " 'found': ['VBN', 'VBD', 'NN', 'JJ', 'VB', 'IN', 'VBP'],\n",
       " 'likely': ['JJ', 'RB'],\n",
       " 'shall': ['MD'],\n",
       " 'find': ['VB', 'VBP'],\n",
       " 'No—Gatsby': ['NNP'],\n",
       " 'turned': ['VBD', 'VBN', 'JJ'],\n",
       " 'right': ['RB', 'NN', 'JJ', 'VBD', 'VB', 'VBP'],\n",
       " 'end': ['NN', 'VB', 'JJ', 'VBP'],\n",
       " 'preyed': ['VBD', 'VBN', 'VBP'],\n",
       " 'foul': ['VBD', 'NN', 'JJ', 'VB'],\n",
       " 'dust': ['NN', 'RB', 'VB', 'JJ'],\n",
       " 'floated': ['VBN', 'VBD'],\n",
       " 'wake': ['NN', 'VBP', 'VB'],\n",
       " 'dreams': ['NNS', 'NN', 'VBZ'],\n",
       " 'temporarily': ['RB'],\n",
       " 'closed': ['VBN', 'VBD', 'JJ'],\n",
       " 'interest': ['NN'],\n",
       " 'abortive': ['JJ'],\n",
       " 'sorrows': ['NNS'],\n",
       " 'short-winded': ['JJ'],\n",
       " 'elations': ['NNS'],\n",
       " '--': [':'],\n",
       " 'My': ['PRP$', 'NNP', 'VB'],\n",
       " 'family': ['NN'],\n",
       " 'prominent': ['JJ', 'NN'],\n",
       " 'well-to-do': ['JJ'],\n",
       " 'Middle': ['NNP'],\n",
       " 'Western': ['NNP', 'JJ'],\n",
       " 'city': ['NN'],\n",
       " 'three': ['CD'],\n",
       " 'generations': ['NNS'],\n",
       " 'Carraways': ['NNPS'],\n",
       " 'clan': ['NN'],\n",
       " 'tradition': ['NN'],\n",
       " 're': ['RB', 'JJ', 'NN', 'VB', 'VBP', 'NNS'],\n",
       " 'descended': ['VBN', 'VBD'],\n",
       " 'Dukes': ['NNP'],\n",
       " 'Buccleuch': ['NNP'],\n",
       " 'actual': ['JJ'],\n",
       " 'founder': ['NN'],\n",
       " 'line': ['NN'],\n",
       " 'grandfather': ['NN', 'RB', 'JJ'],\n",
       " 'brother': ['NN', 'VBP', 'RB', 'VB'],\n",
       " 'here': ['RB'],\n",
       " 'fifty-one': ['NN'],\n",
       " 'sent': ['VBD', 'VBN', 'NN', 'VB'],\n",
       " 'substitute': ['NN', 'VB'],\n",
       " 'Civil': ['NNP'],\n",
       " 'War': ['NNP'],\n",
       " 'started': ['VBD', 'VBN', 'JJ'],\n",
       " 'wholesale': ['JJ'],\n",
       " 'hardware': ['NN'],\n",
       " 'business': ['NN'],\n",
       " 'carries': ['VBZ'],\n",
       " 'today': ['NN'],\n",
       " 'saw': ['VBD', 'JJ', 'RB', 'VBP', 'NN', 'VBZ', 'VB'],\n",
       " 'great-uncle': ['NN'],\n",
       " 'supposed': ['VBN', 'VBD'],\n",
       " 'look': ['VB', 'NN', 'VBP', 'CC'],\n",
       " 'him—with': ['NN'],\n",
       " 'special': ['JJ'],\n",
       " 'reference': ['NN'],\n",
       " 'rather': ['RB'],\n",
       " 'hard-boiled': ['JJ'],\n",
       " 'painting': ['NN', 'VBG'],\n",
       " 'hangs': ['VBZ', 'NNS'],\n",
       " 'office': ['NN'],\n",
       " 'graduated': ['VBD'],\n",
       " 'New': ['NNP'],\n",
       " 'Haven': ['NNP'],\n",
       " '1915': ['CD'],\n",
       " 'quarter': ['NN'],\n",
       " 'century': ['NN'],\n",
       " 'later': ['JJ', 'RB', 'RBR', 'JJR'],\n",
       " 'participated': ['VBD', 'VBN'],\n",
       " 'delayed': ['VBD', 'VBN'],\n",
       " 'Teutonic': ['NNP'],\n",
       " 'migration': ['NN'],\n",
       " 'known': ['VBN', 'JJ', 'VB', 'NN', 'VBZ'],\n",
       " 'enjoyed': ['VBD', 'VBN', 'VBZ', 'VB', 'VBP'],\n",
       " 'counter-raid': ['NN'],\n",
       " 'thoroughly': ['RB', 'JJ', 'NN'],\n",
       " 'restless': ['JJ', 'NN'],\n",
       " 'Instead': ['RB'],\n",
       " 'warm': ['JJ', 'VB', 'NN', 'VBP'],\n",
       " 'centre': ['NN', 'VBP'],\n",
       " 'West': ['NNP'],\n",
       " 'now': ['RB'],\n",
       " 'seemed': ['VBZ', 'VBD', 'VBN', 'NN', 'VB'],\n",
       " 'ragged': ['JJ', 'VBN', 'VBD', 'NN'],\n",
       " 'edge': ['NN', 'VB'],\n",
       " 'universe—so': ['JJ'],\n",
       " 'decided': ['VBD', 'VBN', 'JJ'],\n",
       " 'go': ['VB', 'VBP', 'VBN', 'NN'],\n",
       " 'learn': ['VB', 'VBP', 'NN'],\n",
       " 'bond': ['NN'],\n",
       " 'Everybody': ['NN', 'NNP'],\n",
       " 'knew': ['VBD',\n",
       "  'NNP',\n",
       "  'VB',\n",
       "  'RB',\n",
       "  'NNS',\n",
       "  'VBZ',\n",
       "  'VBP',\n",
       "  'NN',\n",
       "  'VBN',\n",
       "  'FW',\n",
       "  'JJ'],\n",
       " 'could': ['MD'],\n",
       " 'support': ['VB', 'NN', 'VBP'],\n",
       " 'single': ['JJ'],\n",
       " 'All': ['DT', 'PDT', 'NNP', 'CC'],\n",
       " 'aunts': ['NNS'],\n",
       " 'uncles': ['NNS'],\n",
       " 'talked': ['VBD', 'VBN'],\n",
       " 'choosing': ['VBG'],\n",
       " 'prep': ['JJ'],\n",
       " 'school': ['NN'],\n",
       " 'finally': ['RB'],\n",
       " 'said': ['VBD'],\n",
       " 'Why—ye-es': ['NNP'],\n",
       " 'very': ['RB', 'NN', 'JJ', 'NNS'],\n",
       " 'grave': ['JJ', 'NN', 'VBP', 'VB', 'RB'],\n",
       " 'hesitant': ['JJ'],\n",
       " 'faces': ['VBZ'],\n",
       " 'Father': ['NNP', 'NN'],\n",
       " 'agreed': ['VBD', 'VBN', 'JJ'],\n",
       " 'finance': ['VB', 'NN'],\n",
       " 'year': ['NN'],\n",
       " 'various': ['JJ'],\n",
       " 'delays': ['NNS'],\n",
       " 'permanently': ['RB'],\n",
       " 'thought': ['VBD', 'NN', 'VBN', 'JJ', 'VBP', 'VB'],\n",
       " 'spring': ['NN', 'JJ', 'VBG', 'VB'],\n",
       " 'twenty-two': ['NN', 'JJ'],\n",
       " 'practical': ['JJ'],\n",
       " 'thing': ['NN'],\n",
       " 'rooms': ['NNS'],\n",
       " 'season': ['NN'],\n",
       " 'left': ['VBN', 'JJ', 'VBD', 'NN', 'VB', 'NNS', 'VBP', 'JJR', 'VBZ'],\n",
       " 'wide': ['JJ'],\n",
       " 'lawns': ['NNS', 'NN'],\n",
       " 'friendly': ['JJ', 'RB'],\n",
       " 'trees': ['NNS'],\n",
       " 'take': ['VBP', 'VB', 'NN'],\n",
       " 'house': ['NN'],\n",
       " 'together': ['RB', 'NN'],\n",
       " 'commuting': ['NN'],\n",
       " 'town': ['NN'],\n",
       " 'sounded': ['VBD', 'VBN'],\n",
       " 'idea': ['NN'],\n",
       " 'weather-beaten': ['JJ'],\n",
       " 'cardboard': ['NN', 'JJ'],\n",
       " 'bungalow': ['NN'],\n",
       " 'eighty': ['FW', 'JJ', 'NN', 'VB', 'RB'],\n",
       " 'month': ['NN'],\n",
       " 'minute': ['NN', 'JJ', 'VB'],\n",
       " 'firm': ['NN', 'VBZ', 'JJ'],\n",
       " 'ordered': ['VBD', 'VBN', 'JJ'],\n",
       " 'Washington': ['NNP'],\n",
       " 'went': ['VBD'],\n",
       " 'alone': ['RB', 'NN', 'JJ', 'VB', 'VBP', 'IN'],\n",
       " 'dog—at': ['NN'],\n",
       " 'days': ['NNS'],\n",
       " 'until': ['IN'],\n",
       " 'ran': ['VBD', 'NN', 'VBP'],\n",
       " 'away—and': ['RP'],\n",
       " 'old': ['JJ'],\n",
       " 'Dodge': ['NNP'],\n",
       " 'Finnish': ['JJ'],\n",
       " 'woman': ['NN'],\n",
       " 'bed': ['NN', 'VB', 'VBD', 'VBN'],\n",
       " 'cooked': ['VBD', 'VBN', 'JJ'],\n",
       " 'breakfast': ['NN', 'VB', 'VBN'],\n",
       " 'muttered': ['VBD'],\n",
       " 'wisdom': ['NN', 'VB'],\n",
       " 'herself': ['VB', 'PRP', 'NN'],\n",
       " 'electric': ['JJ'],\n",
       " 'stove': ['NN', 'VBN', 'VB', 'RB', 'JJ', 'VBP', 'IN'],\n",
       " 'It': ['PRP'],\n",
       " 'lonely': ['RB', 'JJ'],\n",
       " 'day': ['NN'],\n",
       " 'morning': ['NN'],\n",
       " 'arrived': ['VBD', 'VBN', 'JJ'],\n",
       " 'stopped': ['VBD', 'VBN', 'NN', 'JJ'],\n",
       " 'road': ['NN'],\n",
       " 'How': ['WRB', 'NNP', 'VB'],\n",
       " 'get': ['VB', 'VBP', 'NN'],\n",
       " 'Egg': ['NNP'],\n",
       " 'village': ['NN'],\n",
       " '?': ['.'],\n",
       " 'asked': ['VBD', 'VBN', 'JJ'],\n",
       " 'helplessly': ['RB'],\n",
       " 'walked': ['VBD', 'VBN', 'VB'],\n",
       " 'longer': ['RBR', 'RB', 'JJR', 'NN'],\n",
       " 'guide': ['NN', 'VB'],\n",
       " 'pathfinder': ['NN'],\n",
       " 'original': ['JJ'],\n",
       " 'settler': ['NN'],\n",
       " 'casually': ['RB'],\n",
       " 'conferred': ['VBN', 'VBD'],\n",
       " 'freedom': ['NN', 'VB'],\n",
       " 'neighbourhood': ['NN'],\n",
       " 'sunshine': ['NN'],\n",
       " 'bursts': ['NNS'],\n",
       " 'leaves': ['NNS', 'VBZ'],\n",
       " 'growing': ['VBG', 'NN'],\n",
       " 'things': ['NNS'],\n",
       " 'grow': ['VBP', 'VB', 'NN'],\n",
       " 'fast': ['JJ', 'RB', 'VB', 'NN', 'VBN', 'VBP'],\n",
       " 'movies': ['NNS'],\n",
       " 'familiar': ['JJ'],\n",
       " 'conviction': ['NN'],\n",
       " 'beginning': ['VBG', 'NN'],\n",
       " 'summer': ['NN'],\n",
       " 'There': ['EX'],\n",
       " 'much': ['JJ', 'RB'],\n",
       " 'read': ['VB', 'VBP', 'VBD', 'VBN', 'NN', 'JJ'],\n",
       " 'fine': ['JJ', 'NN', 'VBP', 'VB'],\n",
       " 'health': ['NN'],\n",
       " 'pulled': ['VBN', 'VBD', 'JJ'],\n",
       " 'down': ['RP', 'RB', 'IN', 'NN', 'VBN', 'JJ'],\n",
       " 'breath-giving': ['JJ'],\n",
       " 'air': ['NN'],\n",
       " 'bought': ['VBD', 'VBN', 'JJ', 'VB'],\n",
       " 'dozen': ['NN'],\n",
       " 'volumes': ['NNS'],\n",
       " 'banking': ['NN'],\n",
       " 'credit': ['NN'],\n",
       " 'investment': ['NN'],\n",
       " 'securities': ['NNS'],\n",
       " 'stood': ['VBD', 'VBN', 'NN', 'VBZ', 'VB', 'VBP', 'JJ'],\n",
       " 'shelf': ['NN'],\n",
       " 'red': ['JJ', 'VBD', 'VBN', 'NN'],\n",
       " 'new': ['JJ'],\n",
       " 'money': ['NN'],\n",
       " 'mint': ['NN'],\n",
       " 'promising': ['VBG', 'JJ'],\n",
       " 'unfold': ['VB', 'VBP', 'JJ'],\n",
       " 'shining': ['VBG', 'NN', 'JJ'],\n",
       " 'secrets': ['NNS'],\n",
       " 'only': ['RB', 'JJ'],\n",
       " 'Midas': ['NNP'],\n",
       " 'Morgan': ['NNP'],\n",
       " 'Maecenas': ['NNP'],\n",
       " 'intention': ['NN'],\n",
       " 'reading': ['VBG', 'NN'],\n",
       " 'books': ['NNS'],\n",
       " 'besides': ['IN', 'VBZ', 'NNS'],\n",
       " 'literary': ['JJ', 'VB'],\n",
       " 'college—one': ['JJ'],\n",
       " 'wrote': ['VBD'],\n",
       " 'solemn': ['JJ', 'NN', 'RB', 'VBP', 'VB'],\n",
       " 'editorials': ['NNS'],\n",
       " 'Yale': ['NNP', 'JJ'],\n",
       " 'News—and': ['NNP'],\n",
       " 'going': ['VBG'],\n",
       " 'bring': ['VB', 'NN', 'VBP', 'VBG'],\n",
       " 'become': ['VB', 'VBN', 'JJ', 'VBP', 'NN', 'VBZ'],\n",
       " 'limited': ['JJ', 'VBD', 'VBN'],\n",
       " 'specialists': ['NNS'],\n",
       " 'well-rounded': ['JJ'],\n",
       " 'man.': ['NN', 'VB'],\n",
       " 'isn': ['NN', 'JJ', 'VBZ'],\n",
       " 'epigram—life': ['NN'],\n",
       " 'successfully': ['RB'],\n",
       " 'looked': ['VBN', 'VBD', 'JJ'],\n",
       " 'window': ['NN', 'VBD', 'VBP'],\n",
       " 'chance': ['NN'],\n",
       " 'should': ['MD'],\n",
       " 'rented': ['VBN', 'VBD'],\n",
       " 'strangest': ['JJS', 'JJ', 'NN'],\n",
       " 'communities': ['NNS'],\n",
       " 'North': ['NNP', 'JJ', 'RB'],\n",
       " 'America': ['NNP'],\n",
       " 'slender': ['NN', 'JJR', 'RBR', 'JJ', 'VB'],\n",
       " 'island': ['NN'],\n",
       " 'extends': ['VBZ'],\n",
       " 'due': ['JJ'],\n",
       " 'east': ['RB', 'NN', 'JJ', 'VBP', 'JJS', 'VB'],\n",
       " 'York—and': ['NNP'],\n",
       " 'among': ['IN'],\n",
       " 'natural': ['JJ'],\n",
       " 'curiosities': ['NNS'],\n",
       " 'two': ['CD'],\n",
       " 'unusual': ['JJ'],\n",
       " 'formations': ['NNS'],\n",
       " 'land': ['NN', 'JJ', 'VB', 'VBP'],\n",
       " 'Twenty': ['CD'],\n",
       " 'pair': ['NN'],\n",
       " 'enormous': ['JJ'],\n",
       " 'eggs': ['NNS'],\n",
       " 'identical': ['JJ'],\n",
       " 'contour': ['NN'],\n",
       " 'separated': ['VBN', 'VBD'],\n",
       " 'courtesy': ['NN', 'VBG'],\n",
       " 'bay': ['NN', 'VBD'],\n",
       " 'jut': ['NN'],\n",
       " 'domesticated': ['JJ', 'VBN'],\n",
       " 'body': ['NN', 'VB'],\n",
       " 'salt': ['JJ', 'NN'],\n",
       " 'water': ['NN'],\n",
       " 'hemisphere': ['RB', 'NN'],\n",
       " 'barnyard': ['NN'],\n",
       " 'Long': ['NNP', 'JJ', 'RB'],\n",
       " 'Island': ['NNP'],\n",
       " 'Sound': ['NNP'],\n",
       " 'They': ['PRP'],\n",
       " 'perfect': ['JJ', 'VBP', 'NN', 'VB'],\n",
       " 'ovals—like': ['IN'],\n",
       " 'egg': ['NN'],\n",
       " 'Columbus': ['NNP'],\n",
       " 'story': ['NN'],\n",
       " 'both': ['DT', 'CC', 'VB'],\n",
       " 'crushed': ['JJ', 'VBN', 'VBD'],\n",
       " 'flat': ['NN', 'JJ'],\n",
       " 'contact': ['NN', 'VB', 'VBP'],\n",
       " 'end—but': ['VBP'],\n",
       " 'their': ['PRP$'],\n",
       " 'physical': ['JJ'],\n",
       " 'resemblance': ['NN'],\n",
       " 'source': ['NN'],\n",
       " 'perpetual': ['JJ'],\n",
       " 'wonder': ['NN', 'VBP', 'VB'],\n",
       " 'gulls': ['NNS', 'VBZ'],\n",
       " 'fly': ['VBP', 'VB', 'NN', 'JJ'],\n",
       " 'overhead': ['RB', 'NN', 'VBP', 'JJ', 'VB'],\n",
       " 'To': ['TO'],\n",
       " 'wingless': ['NN'],\n",
       " 'interesting': ['JJ', 'VBG', 'NN'],\n",
       " 'phenomenon': ['NN'],\n",
       " 'dissimilarity': ['NN'],\n",
       " 'every': ['DT'],\n",
       " 'particular': ['JJ', 'NN'],\n",
       " 'except': ['IN', 'VB', 'VBP'],\n",
       " 'shape': ['NN', 'VB'],\n",
       " 'size': ['NN'],\n",
       " 'lived': ['VBD', 'JJ', 'VBN', 'VBZ'],\n",
       " 'the—well': ['NN'],\n",
       " 'less': ['RBR', 'JJR', 'NN', 'CC', 'JJS'],\n",
       " 'fashionable': ['JJ'],\n",
       " 'though': ['IN', 'RB', 'VB'],\n",
       " 'superficial': ['JJ'],\n",
       " 'tag': ['NN'],\n",
       " 'bizarre': ['NN', 'JJ'],\n",
       " 'sinister': ['NN', 'JJ'],\n",
       " 'contrast': ['NN'],\n",
       " 'between': ['IN'],\n",
       " 'tip': ['NN', 'VB'],\n",
       " 'fifty': ['JJ', 'VB', 'CD', 'NN', 'VBD'],\n",
       " 'yards': ['NNS'],\n",
       " 'squeezed': ['VBD'],\n",
       " 'huge': ['JJ'],\n",
       " 'places': ['NNS', 'VBZ'],\n",
       " 'twelve': ['NN', 'RB', 'JJ', 'VB', 'NNS', 'CD', 'VBN', 'VBG'],\n",
       " 'fifteen': ['JJ', 'NN'],\n",
       " 'colossal': ['NN', 'JJ'],\n",
       " 'affair': ['NN'],\n",
       " 'standard—it': ['NN'],\n",
       " 'factual': ['JJ'],\n",
       " 'imitation': ['NN'],\n",
       " 'Hôtel': ['NNP'],\n",
       " 'de': ['FW', 'NNP', 'IN', 'VB', 'JJ', 'VBN', 'RB'],\n",
       " 'Ville': ['NNP'],\n",
       " 'Normandy': ['NNP'],\n",
       " 'tower': ['NN', 'JJR'],\n",
       " 'side': ['NN', 'VB', 'JJ', 'RB', 'VBP'],\n",
       " 'spanking': ['VBG'],\n",
       " 'thin': ['JJ', 'NN', 'VBZ', 'VB'],\n",
       " 'beard': ['NN', 'IN'],\n",
       " 'raw': ['JJ', 'NN', 'VB'],\n",
       " 'ivy': ['NN', 'JJ'],\n",
       " 'marble': ['JJ', 'NN'],\n",
       " 'swimming': ['NN', 'VBG', 'JJ'],\n",
       " 'pool': ['NN'],\n",
       " 'forty': ['JJ', 'NN', 'CD', 'VB'],\n",
       " 'acres': ['NNS'],\n",
       " 'lawn': ['NN'],\n",
       " 'garden': ['NN'],\n",
       " 'mansion': ['NN'],\n",
       " 'Or': ['CC', 'NNP'],\n",
       " 'know': ['VBP', 'VB', 'NNS', 'VBZ', 'JJ', 'NN', 'VBD', 'VBN', 'NNP'],\n",
       " 'Mr.': ['NNP'],\n",
       " 'inhabited': ['VBN', 'VBD', 'JJ'],\n",
       " 'gentleman': ['NN'],\n",
       " 'own': ['JJ', 'VBP', 'VB'],\n",
       " 'eyesore': ['NN'],\n",
       " 'small': ['JJ'],\n",
       " 'overlooked': ['VBN', 'VBD'],\n",
       " 'view': ['NN', 'VB', 'VBP'],\n",
       " 'partial': ['JJ'],\n",
       " 'neighbour': ['JJ', 'NN'],\n",
       " 'consoling': ['VBG'],\n",
       " 'proximity': ['NN'],\n",
       " 'millionaires—all': ['NN'],\n",
       " 'dollars': ['NNS'],\n",
       " 'Across': ['IN', 'NNP'],\n",
       " 'white': ['JJ'],\n",
       " 'palaces': ['NNS'],\n",
       " 'glittered': ['VBD', 'VBN'],\n",
       " 'along': ['IN', 'RB', 'RP', 'JJ', 'NN'],\n",
       " 'history': ['NN'],\n",
       " 'really': ['RB'],\n",
       " 'begins': ['VBZ', 'NNS'],\n",
       " 'evening': ['NN', 'VBG'],\n",
       " 'drove': ['VBD', 'VB', 'NN'],\n",
       " 'dinner': ['NN', 'VB'],\n",
       " 'Tom': ['NNP'],\n",
       " 'Buchanans': ['NNPS', 'NNP'],\n",
       " 'Daisy': ['NNP', 'NN', 'VB'],\n",
       " 'second': ['JJ', 'NN', 'VB'],\n",
       " 'cousin': ['NN'],\n",
       " 'once': ['RB', 'IN', 'NN', 'VB'],\n",
       " 'removed': ['VBN', 'VBD', 'NN'],\n",
       " 'war': ['NN'],\n",
       " 'spent': ['VBD', 'VBN', 'NN', 'VB', 'VBP', 'JJ'],\n",
       " 'Chicago': ['NNP'],\n",
       " 'Her': ['PRP$', 'NNP'],\n",
       " 'husband': ['NN'],\n",
       " 'accomplishments': ['NNS'],\n",
       " 'powerful': ['JJ'],\n",
       " 'ends': ['NNS', 'VBZ', 'VBP'],\n",
       " 'played': ['VBD', 'VBN', 'JJ', 'VBP', 'VBZ'],\n",
       " 'football': ['NN'],\n",
       " 'Haven—a': ['NNP'],\n",
       " 'national': ['JJ'],\n",
       " 'figure': ['NN', 'VB', 'VBP'],\n",
       " 'reach': ['VBP', 'VB', 'NN'],\n",
       " 'acute': ['NN', 'JJ'],\n",
       " 'excellence': ['NN'],\n",
       " 'twenty-one': ['NN', 'JJ'],\n",
       " 'afterward': ['RB', 'IN', 'NN', 'CC'],\n",
       " 'savours': ['VBZ'],\n",
       " 'anticlimax': ['NN'],\n",
       " 'His': ['PRP$'],\n",
       " 'enormously': ['RB'],\n",
       " 'wealthy—even': ['VBN'],\n",
       " 'reproach—but': ['NN'],\n",
       " 'fashion': ['NN'],\n",
       " 'took': ['VBD'],\n",
       " 'your': ['PRP$'],\n",
       " 'breath': ['NN'],\n",
       " 'instance': ['NN'],\n",
       " 'brought': ['VBD', 'VBN', 'NN', 'JJ', 'VB'],\n",
       " 'string': ['NN', 'VBG'],\n",
       " 'polo': ['JJ', 'NN'],\n",
       " 'ponies': ['NNS'],\n",
       " 'Lake': ['NNP'],\n",
       " 'Forest': ['NNP'],\n",
       " 'realize': ['VB', 'VBP', 'NN'],\n",
       " 'generation': ['NN'],\n",
       " 'wealthy': ['JJ', 'NN'],\n",
       " 'enough': ['RB', 'JJ', 'NN', 'VB', 'IN'],\n",
       " 'Why': ['WRB'],\n",
       " 'France': ['NNP'],\n",
       " 'reason': ['NN'],\n",
       " 'drifted': ['VBD', 'VBN'],\n",
       " 'unrestfully': ['RB'],\n",
       " 'wherever': ['JJ', 'NN', 'WRB', 'RB', 'IN', 'WP'],\n",
       " 'rich': ['JJ', 'VB', 'VBP', 'NN'],\n",
       " 'permanent': ['JJ', 'NN'],\n",
       " 'telephone': ['NN'],\n",
       " 'believe': ['VBP', 'RP', 'VB', 'CC'],\n",
       " 'it—I': ['NN', 'NNS'],\n",
       " 'sight': ['NN', 'VBN', 'JJ', 'VBD', 'VB', 'RB'],\n",
       " 'would': ['MD'],\n",
       " 'drift': ['VB', 'NN', 'VBP'],\n",
       " 'seeking': ['VBG'],\n",
       " 'wistfully': ['RB'],\n",
       " 'dramatic': ['JJ'],\n",
       " 'turbulence': ['NN'],\n",
       " 'irrecoverable': ['JJ'],\n",
       " 'game': ['NN'],\n",
       " 'happened': ['VBD', 'VBN'],\n",
       " 'windy': ['NN', 'JJ'],\n",
       " 'see': ['VB', 'VBP', 'NN', 'JJ'],\n",
       " 'friends': ['NNS', 'VBZ', 'NNPS', 'VBP'],\n",
       " 'whom': ['WP'],\n",
       " 'scarcely': ['RB'],\n",
       " 'Their': ['PRP$', 'NNP'],\n",
       " 'even': ['RB', 'JJ', 'VB'],\n",
       " 'elaborate': ['JJ', 'VB'],\n",
       " 'expected': ['VBD', 'VBN', 'JJ'],\n",
       " 'cheerful': ['JJ', 'NN'],\n",
       " 'red-and-white': ['JJ'],\n",
       " 'Georgian': ['JJ'],\n",
       " 'Colonial': ['NNP'],\n",
       " 'overlooking': ['VBG'],\n",
       " 'beach': ['NN', 'VB'],\n",
       " 'towards': ['IN', 'VB', 'NNS', 'VBD', 'VBZ', 'JJ', 'VBP'],\n",
       " 'front': ['NN', 'JJ', 'RB', 'VB'],\n",
       " 'door': ['NN'],\n",
       " 'mile': ['NN', 'JJ'],\n",
       " 'jumping': ['VBG', 'NN'],\n",
       " 'sundials': ['NNS'],\n",
       " 'brick': ['NN'],\n",
       " 'walks': ['NNS', 'VBZ', 'NN', 'VBP'],\n",
       " 'burning': ['VBG', 'NN'],\n",
       " 'gardens—finally': ['RB'],\n",
       " 'reached': ['VBD', 'VBN'],\n",
       " 'drifting': ['VBG', 'NN'],\n",
       " 'bright': ['JJ', 'VBN', 'NN', 'VBZ', 'VBD'],\n",
       " 'vines': ['NNS'],\n",
       " 'momentum': ['NN'],\n",
       " 'its': ['PRP$'],\n",
       " 'run': ['NN', 'VB', 'VBP', 'VBN'],\n",
       " 'broken': ['VBN', 'JJ', 'NNS', 'VB', 'NN', 'VBD', 'VBZ'],\n",
       " 'French': ['JJ', 'NNP', 'NN'],\n",
       " 'windows': ['NNS', 'VBZ'],\n",
       " 'glowing': ['VBG', 'JJ', 'NN'],\n",
       " 'reflected': ['VBN', 'VBD'],\n",
       " 'open': ['JJ', 'RP', 'VB', 'VBP', 'RB'],\n",
       " 'afternoon': ['NN'],\n",
       " 'Buchanan': ['NNP'],\n",
       " 'riding': ['VBG', 'NN'],\n",
       " 'clothes': ['NNS'],\n",
       " 'standing': ['VBG', 'NN'],\n",
       " 'legs': ['NNS', 'NN', 'JJ', 'VBZ'],\n",
       " 'apart': ['RB', 'NN'],\n",
       " 'porch': ['NN'],\n",
       " 'changed': ['VBN', 'VBD', 'JJ', 'VB'],\n",
       " 'Now': ['RB'],\n",
       " 'sturdy': ['JJ'],\n",
       " 'straw-haired': ['JJ'],\n",
       " 'thirty': ['NN', 'JJ', 'VB', 'CD'],\n",
       " 'mouth': ['NN', 'VB', 'JJ', 'VBD'],\n",
       " 'supercilious': ['JJ'],\n",
       " 'manner': ['NN', 'NNS'],\n",
       " 'Two': ['CD'],\n",
       " 'arrogant': ['JJ'],\n",
       " 'eyes': ['NNS', 'VBP', 'RB'],\n",
       " 'established': ['VBN', 'VBD', 'JJ'],\n",
       " 'dominance': ['NN'],\n",
       " 'face': ['NN', 'VBP', 'VB'],\n",
       " 'appearance': ['NN'],\n",
       " 'leaning': ['VBG', 'NN'],\n",
       " 'aggressively': ['RB'],\n",
       " 'forward': ['RB', 'JJ', 'NN', 'IN'],\n",
       " 'Not': ['RB'],\n",
       " 'effeminate': ['NN'],\n",
       " 'swank': ['NN', 'JJ'],\n",
       " 'hide': ['VB', 'NN', 'VBZ'],\n",
       " 'power': ['NN'],\n",
       " 'body—he': ['NN'],\n",
       " 'fill': ['VB', 'VBP', 'VBN', 'NN'],\n",
       " 'glistening': ['VBG', 'JJ'],\n",
       " 'boots': ['NNS', 'VBP', 'VB'],\n",
       " 'strained': ['VBD', 'JJ', 'VBN'],\n",
       " 'top': ['JJ', 'NN', 'VB'],\n",
       " 'lacing': ['NN', 'VBG'],\n",
       " 'pack': ['NN', 'VBP', 'VB', 'JJ'],\n",
       " 'muscle': ['NN'],\n",
       " 'shifting': ['VBG', 'NN'],\n",
       " 'shoulder': ['NN', 'VB'],\n",
       " 'moved': ['VBD', 'VBN', 'JJ'],\n",
       " 'coat': ['NN'],\n",
       " 'capable': ['JJ', 'NN'],\n",
       " 'leverage—a': ['NN'],\n",
       " 'cruel': ['NN', 'JJ', 'VB'],\n",
       " 'speaking': ['NN', 'VBG'],\n",
       " 'voice': ['NN', 'NNS'],\n",
       " 'gruff': ['NN', 'JJ'],\n",
       " 'husky': ['NN', 'JJ'],\n",
       " 'tenor': ['NN'],\n",
       " 'added': ['VBD', 'VBN', 'JJ'],\n",
       " 'impression': ['NN'],\n",
       " 'fractiousness': ['NN'],\n",
       " 'conveyed': ['VBD', 'JJ', 'VBN'],\n",
       " 'touch': ['NN', 'VB', 'JJ', 'PDT', 'VBP'],\n",
       " 'paternal': ['JJ'],\n",
       " 'contempt': ['NN', 'VB'],\n",
       " 'toward': ['IN'],\n",
       " 'liked—and': ['VBP'],\n",
       " 'hated': ['VBN', 'VBD', 'JJ'],\n",
       " 'guts': ['NNS'],\n",
       " 'think': ['VBP', 'NN', 'VB'],\n",
       " 'opinion': ['NN'],\n",
       " 'these': ['DT'],\n",
       " 'matters': ['NNS', 'VBZ'],\n",
       " 'final': ['JJ'],\n",
       " 'stronger': ['JJR'],\n",
       " 'are.': ['VBP'],\n",
       " 'We': ['PRP'],\n",
       " 'same': ['JJ'],\n",
       " 'senior': ['JJ'],\n",
       " 'society': ['NN', 'VB'],\n",
       " 'while': ['IN', 'NN', 'VB'],\n",
       " 'approved': ['VBD', 'JJ', 'VBN'],\n",
       " 'harsh': ['NN', 'JJ', 'VBZ', 'NNS', 'CC'],\n",
       " 'defiant': ['JJ'],\n",
       " 'wistfulness': ['NN'],\n",
       " 'minutes': ['NNS'],\n",
       " 'sunny': ['JJ', 'NN'],\n",
       " 'got': ['VBD', 'VBN', 'JJ', 'VBP', 'VB', 'NN'],\n",
       " 'nice': ['JJ', 'VB', 'RB', 'NN'],\n",
       " 'place': ['NN', 'VB', 'VBP'],\n",
       " 'flashing': ['VBG', 'JJ', 'NN'],\n",
       " 'restlessly': ['RB'],\n",
       " 'Turning': ['VBG'],\n",
       " 'around': ['IN', 'RB', 'RP', 'VBP', 'NN'],\n",
       " 'arm': ['NN', 'JJ', 'VB'],\n",
       " 'broad': ['JJ'],\n",
       " 'hand': ['NN'],\n",
       " 'vista': ['NN'],\n",
       " 'including': ['VBG'],\n",
       " 'sweep': ['NN', 'VB', 'JJ', 'VBP'],\n",
       " 'sunken': ['JJ', 'NN', 'VBN'],\n",
       " 'Italian': ['JJ', 'NN', 'NNP'],\n",
       " 'half': ['JJ', 'PDT', 'NN', 'DT', 'VB', 'VBP', 'RB', 'VBD', 'VBZ', 'VBN'],\n",
       " 'acre': ['NN'],\n",
       " 'deep': ['JJ', 'NN', 'RB', 'VBP', 'VB'],\n",
       " 'pungent': ['JJ', 'NN'],\n",
       " 'roses': ['NNS', 'VBZ'],\n",
       " 'snub-nosed': ['JJ'],\n",
       " 'motorboat': ['NN'],\n",
       " 'bumped': ['VBD', 'VBN', 'JJ'],\n",
       " 'tide': ['NN', 'RB', 'VB'],\n",
       " 'offshore': ['RB'],\n",
       " 'belonged': ['VBD', 'VBN', 'VBZ'],\n",
       " 'Demaine': ['NNP'],\n",
       " 'oil': ['NN'],\n",
       " 'politely': ['RB'],\n",
       " 'abruptly': ['RB'],\n",
       " 'll': ['JJ', 'RB', 'VBZ', 'JJR', 'NN', 'NNS', 'VBD'],\n",
       " 'inside.': ['JJ'],\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-65ff9377d209>:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.8278453269999773\n",
      "{'pioneer': 0.6586180903547462, 'pioneering': 0.558049227448691, 'pioneers': 0.5162367597988243, 'visionary': 0.5026721864687912, 'leader': 0.43083757445234255, 'hailed': 0.4297488456419351, 'championing': 0.4250173246835439, 'touchstone': 0.42396188858293554, 'pathfinder': 0.42253885416860026, 'fearless': 0.4127582452418442, 'philanthropist': 0.41265734640201734, 'powerhouse': 0.4114014540193822, 'protege': 0.40735593078087945, 'innovators': 0.40501027083394386, 'revered': 0.40389938602123476, 'stalwart': 0.4010675855844121}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# user word\n",
    "user_word = \"trailblazer\"\n",
    "\n",
    "user_word_vec = model.get_word_vector(user_word)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# iterate through numpy array and find vectors that meet a threshold for cosine similarity\n",
    "cos_sim = 0.4\n",
    "for i in range(0, 29153):\n",
    "    current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n",
    "    if current > cos_sim and words[i] != user_word and user_word[0:2] != words[i][0:2] and user_word[0:3] not in words[i]:\n",
    "        results[words[i]] = current\n",
    "        \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "# dictionary: results\n",
    "sorted_values = sorted(results.values(), reverse = True) # Sort the values\n",
    "sorted_dict = {}\n",
    "\n",
    "for i in sorted_values:\n",
    "    for k in results.keys():\n",
    "        if results[k] == i:\n",
    "            sorted_dict[k] = results[k]\n",
    "            break\n",
    "\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pioneer\n",
      "pioneering\n",
      "pioneers\n",
      "visionary\n",
      "leader\n",
      "hailed\n",
      "championing\n",
      "touchstone\n",
      "pathfinder\n",
      "fearless\n",
      "philanthropist\n",
      "powerhouse\n",
      "protege\n",
      "innovators\n",
      "revered\n",
      "stalwart\n"
     ]
    }
   ],
   "source": [
    "for key in sorted_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent = nltk.word_tokenize(\"John was a trailblazer in the field of medicine.\")\n",
    "input_sent_pos = list(nltk.pos_tag(input_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP'), ('was', 'VBD'), ('a', 'DT'), ('trailblazer', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('medicine', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(input_sent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pioneer\n",
      "leader\n",
      "touchstone\n",
      "pathfinder\n",
      "fearless\n",
      "philanthropist\n",
      "powerhouse\n",
      "protege\n"
     ]
    }
   ],
   "source": [
    "for key in sorted_dict:\n",
    "    if input_sent_pos[3][1] in d[key]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN', 'JJ', 'RB']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"fearless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNS']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"innovators\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'panics', 'are', 'more', 'to', 'be', 'dreaded', 'than', 'his', 'most', 'fearless', 'and', 'malicious', 'assaults', '!', 'And', 'thus', 'have', 'these', 'naked']\n",
      "96684\n",
      "['estimation', 'of', 'the', 'encountered', 'peril', ',', 'but', 'that', 'an', 'utterly', 'fearless', 'man', 'is', 'a', 'far', 'more', 'dangerous', 'comrade', 'than', 'a']\n",
      "118923\n",
      "[',', 'a', 'determinate', 'unsurrenderable', 'wilfulness', ',', 'in', 'the', 'fixed', 'and', 'fearless', ',', 'forward', 'dedication', 'of', 'that', 'glance', '.', 'Not', 'a']\n",
      "122910\n",
      "['when', 'Adam', 'walked', 'majestic', 'as', 'a', 'god', ',', 'bluff-bowed', 'and', 'fearless', 'as', 'this', 'mighty', 'steed', '.', 'Whether', 'marching', 'amid', 'his']\n",
      "152355\n",
      "['sort', 'of', 'nervous', 'apprehensiveness', 'touching', 'his', 'own', 'person', 'as', 'any', 'fearless', ',', 'unthinking', 'creature', 'on', 'land', 'or', 'on', 'sea', 'that']\n",
      "176833\n",
      "['canst', 'but', 'kill', ';', 'and', 'all', 'are', 'killed', '.', 'No', 'fearless', 'fool', 'now', 'fronts', 'thee', '.', 'I', 'own', 'thy', 'speechless']\n",
      "289450\n",
      "[',', 'man', '!', 'did', 'I', 'not', 'know', 'thee', 'brave', 'as', 'fearless', 'fire', '(', 'and', 'as', 'mechanical', ')', 'I', 'could', 'swear']\n",
      "309244\n",
      "['ye', 'feel', 'brave', 'men', ',', 'brave', '?', '”', '“', 'As', 'fearless', 'fire', ',', '”', 'cried', 'Stubb', '.', '“', 'And', 'as']\n",
      "313437\n",
      "['as', 'I', 'did', '.', 'Like', 'me', ',', 'you', 'acted', 'the', 'fearless', 'warrior', 'who', 'has', 'no', 'grievances', '.', 'But', 'secretly', 'you']\n",
      "663965\n",
      "['gazes', 'on', 'your', 'misery', '.', 'Beware', ';', 'for', 'I', 'am', 'fearless', ',', 'and', 'therefore', 'powerful', '.', 'I', 'will', 'watch', 'with']\n",
      "1054608\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text)):\n",
    "    if text[i] == \"fearless\":\n",
    "        print(text[i-10:i+10])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sort', 'NN'), ('of', 'IN'), ('nervous', 'JJ'), ('apprehensiveness', 'NN'), ('touching', 'VBG'), ('his', 'PRP$'), ('own', 'JJ'), ('person', 'NN'), ('as', 'IN'), ('any', 'DT'), ('fearless', 'NN'), (',', ','), ('unthinking', 'JJ'), ('creature', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "input_sent = nltk.word_tokenize(\"sort of nervous apprehensiveness touching his own person as any fearless, unthinking creature\")\n",
    "input_sent_pos = list(nltk.pos_tag(input_sent))\n",
    "print(input_sent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Great',\n",
       " 'Gatsby',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\ufeffThe', 'NN'),\n",
       " ('Project', 'NNP'),\n",
       " ('Gutenberg', 'NNP'),\n",
       " ('eBook', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('The', 'DT'),\n",
       " ('Great', 'NNP'),\n",
       " ('Gatsby', 'NNP'),\n",
       " (',', ','),\n",
       " ('by', 'IN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sort', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('nervous', 'JJ'),\n",
       " ('apprehensiveness', 'NN'),\n",
       " ('touching', 'VBG'),\n",
       " ('his', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('person', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('fearless', 'NN'),\n",
       " (',', ','),\n",
       " ('unthinking', 'JJ'),\n",
       " ('creature', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('land', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('on', 'IN'),\n",
       " ('sea', 'NN'),\n",
       " ('that', 'IN')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[176823:176843]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent = nltk.word_tokenize(\"he is a utterly fearless person!\")\n",
    "input_sent_pos = list(nltk.pos_tag(input_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('utterly', 'JJ'),\n",
       " ('fearless', 'NN'),\n",
       " ('person', 'NN'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tag() missing 1 required positional argument: 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-4c6485b77acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStanfordTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mStanfordTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test this\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtext_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sort of nervous apprehensiveness touching his own person as any fearless, unthinking creature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tag() missing 1 required positional argument: 'tokens'"
     ]
    }
   ],
   "source": [
    "# running the Stanford POS Tagger from NLTK\n",
    " \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "\n",
    "StanfordTagger.tag(\"test this\")\n",
    " \n",
    "text_tok = nltk.word_tokenize(\"sort of nervous apprehensiveness touching his own person as any fearless, unthinking creature\")\n",
    " \n",
    "# print(text_tok)\n",
    "pos_tagged = StanfordTagger.tag(text_tok)\n",
    " \n",
    "# print the list of tuples: (word,word_class)\n",
    "print(pos_tagged)\n",
    " \n",
    "# for loop to extract the elements of the tuples in the pos_tagged list\n",
    "# print the word and the pos_tag with the underscore as a delimiter\n",
    "for word,word_class in pos_tagged:\n",
    "    print(word + \"_\" + word_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n",
    "from nltk.parse import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Parser\n",
    ">>> parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "# Parse tokenized text.\n",
    ">>> list(parser.parse('What is the airspeed of an unladen swallow ?'.split()))\n",
    "[Tree('ROOT', [Tree('SBARQ', [Tree('WHNP', [Tree('WP', ['What'])]), Tree('SQ', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['airspeed'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['an']), Tree('JJ', ['unladen'])])]), Tree('S', [Tree('VP', [Tree('VB', ['swallow'])])])])]), Tree('.', ['?'])])])]\n",
    "\n",
    "# Parse raw string.\n",
    ">>> list(parser.raw_parse('What is the airspeed of an unladen swallow ?'))\n",
    "[Tree('ROOT', [Tree('SBARQ', [Tree('WHNP', [Tree('WP', ['What'])]), Tree('SQ', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['airspeed'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['an']), Tree('JJ', ['unladen'])])]), Tree('S', [Tree('VP', [Tree('VB', ['swallow'])])])])]), Tree('.', ['?'])])])]\n",
    "\n",
    "# Neural Dependency Parser\n",
    ">>> from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    ">>> dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    ">>> parses = dep_parser.parse('What is the airspeed of an unladen swallow ?'.split())\n",
    ">>> [[(governor, dep, dependent) for governor, dep, dependent in parse.triples()] for parse in parses]\n",
    "[[(('What', 'WP'), 'cop', ('is', 'VBZ')), (('What', 'WP'), 'nsubj', ('airspeed', 'NN')), (('airspeed', 'NN'), 'det', ('the', 'DT')), (('airspeed', 'NN'), 'nmod', ('swallow', 'VB')), (('swallow', 'VB'), 'case', ('of', 'IN')), (('swallow', 'VB'), 'det', ('an', 'DT')), (('swallow', 'VB'), 'amod', ('unladen', 'JJ')), (('What', 'WP'), 'punct', ('?', '.'))]]\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    ">>> parser = CoreNLPParser(url='http://localhost:9000')\n",
    ">>> list(parser.tokenize('What is the airspeed of an unladen swallow?'))\n",
    "['What', 'is', 'the', 'airspeed', 'of', 'an', 'unladen', 'swallow', '?']\n",
    "\n",
    "# POS Tagger\n",
    ">>> pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    ">>> list(pos_tagger.tag('What is the airspeed of an unladen swallow ?'.split()))\n",
    "[('What', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('airspeed', 'NN'), ('of', 'IN'), ('an', 'DT'), ('unladen', 'JJ'), ('swallow', 'VB'), ('?', '.')]\n",
    "\n",
    "# NER Tagger\n",
    ">>> ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    ">>> list(ner_tagger.tag(('Rami Eid is studying at Stony Brook University in NY'.split())))\n",
    "[('Rami', 'PERSON'), ('Eid', 'PERSON'), ('is', 'O'), ('studying', 'O'), ('at', 'O'), ('Stony', 'ORGANIZATION'), ('Brook', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('in', 'O'), ('NY', 'STATE_OR_PROVINCE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roadhouse', 'NN'),\n",
       " ('next', 'JJ'),\n",
       " ('door', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('came', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('disconcerting', 'VBG'),\n",
       " ('ride', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('hadn', 'VBP'),\n",
       " (\"'\", \"''\"),\n",
       " ('t', 'NN')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "list(pos_tagger.tag('he is an utterly fearless, simple, and thoughtless person'.split()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sent = \"This is a sentence, and I am using it as a test.\"\n",
    "\n",
    "sent = ['roadhouse', 'next', 'door', '.', 'And', 'then', 'came', 'that', 'disconcerting', 'ride', '.', 'We', 'hadn', '’', 't']\n",
    "list(pos_tagger.tag(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
