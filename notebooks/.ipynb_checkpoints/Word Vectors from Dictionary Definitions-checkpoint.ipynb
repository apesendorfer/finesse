{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "# cosine similarity of word vectors\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan:\n",
    "\n",
    "## 1) Create word vectors based on dictionary definition averages\n",
    "\n",
    "## 2) Increase the weight of words that are in the TF-IDF sets\n",
    "\n",
    "## 3) Normalize all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fasttext model. vectors have 300 dimensions\n",
    "\n",
    "model = fasttext.load_model(\"/Users/alex/result/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"tfidf_wiki.txt\", \"r\")\n",
    "\n",
    "tfidf_words = f.read().split()\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(tfidf_words[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235892"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56057"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9302"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(brown.words(categories='fiction')))\n",
    "print(len(set(brown.words(categories='fiction'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  45.044336163000025\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#create numpy array to store word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(100, 300))\n",
    "words_arr = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "for word in words.words()[0:50]:\n",
    "    #print(word)\n",
    "    meaning = dictionary.meaning(word, disable_errors=True)\n",
    "    \n",
    "    if meaning == None:\n",
    "        continue\n",
    "    else:\n",
    "        for pos in meaning:\n",
    "            defn = meaning[pos]\n",
    "            defn_words = defn[0].split()\n",
    "            vector_sum = [0]*300\n",
    "            for wrd in defn_words:\n",
    "                vector_sum += model.get_word_vector(wrd)\n",
    "            avg_vec = vector_sum / float(len(defn_words))\n",
    "#             if count == 50:\n",
    "#                 break\n",
    "            arr[count] = avg_vec\n",
    "            #print(arr[count])\n",
    "            #print(pos)\n",
    "            count += 1\n",
    "            words_arr.append(word)\n",
    "            #print(word)\n",
    "            #print(\"------------\")\n",
    "#         if count == 50:\n",
    "#                 break\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  116.62358172999984\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#create numpy array to store word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(100, 300))\n",
    "words_arr = []\n",
    "\n",
    "words_set = list(set(brown.words(categories='fiction')))\n",
    "\n",
    "count = 0\n",
    "for word in words_set[0:100]:\n",
    "\n",
    "    if count == 100:\n",
    "        break\n",
    "    \n",
    "    meaning = dictionary.meaning(word, disable_errors=True)\n",
    "    \n",
    "    if meaning == None:\n",
    "        continue\n",
    "    else:\n",
    "        if \"Adjective\" in meaning:\n",
    "            defn = meaning[\"Adjective\"]\n",
    "            defn_words = defn[0].split()\n",
    "            vector_sum = [0]*300\n",
    "            for wrd in defn_words:\n",
    "                vector_sum += model.get_word_vector(wrd)\n",
    "            arr[count] = vector_sum / float(len(defn_words))\n",
    "            #print(arr[count])\n",
    "            #print(pos)\n",
    "            count += 1\n",
    "            words_arr.append(word)\n",
    "            \n",
    "\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventurous', 'gone', 'unreal', 'high-ceilinged', 'inappropriate', 'scrub', 'manufactured', 'finished', 'spontaneous', 'punctured', 'polite', 'hectic', 'attired', 'impending', 'sensed', 'shabby', 'placed', 'supercilious', 'caliche-topped', 'sorrel']\n"
     ]
    }
   ],
   "source": [
    "print(words_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the trait of lacking restraint or control; reckless freedom from inhibition or worry\n",
      "the\n",
      "trait\n",
      "of\n",
      "lacking\n",
      "restraint\n",
      "or\n",
      "control;\n",
      "reckless\n",
      "freedom\n",
      "from\n",
      "inhibition\n",
      "or\n",
      "worry\n",
      "Time:  0.0018246439999529684\n"
     ]
    }
   ],
   "source": [
    "word = \"abandon\"\n",
    "\n",
    "word_dict = {'Noun': ['the trait of lacking restraint or control; reckless freedom from inhibition or worry', 'a feeling of extreme emotional intensity'], 'Verb': ['forsake, leave behind', 'give up with the intent of never claiming again', 'leave behind empty; move out of', 'stop maintaining or insisting on; of ideas or claims', 'leave someone who needs or counts on you; leave in the lurch']}\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "defn = word_dict[\"Noun\"][0]\n",
    "\n",
    "print(defn)\n",
    "\n",
    "vector_sum = [0]*300\n",
    "\n",
    "for wrd in defn.split():\n",
    "    print(wrd)\n",
    "    vector_sum += model.get_word_vector(wrd)\n",
    "    \n",
    "arr[0] = vector_sum / float(len(defn_words))\n",
    "words_arr.append(word)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adjective': ['willing to undertake or seeking out new and daring enterprises']}\n",
      "{'Verb': ['change location; move, travel, or proceed, also metaphorically', 'follow a procedure or take a course', 'move away from a place into another direction', 'enter or assume a certain state or condition', 'be awarded; be allotted', 'have a particular form', 'stretch out over a distance, space, time, or scope; run or extend between two points or beyond a certain point', 'follow a certain course', 'be abolished or discarded', 'be or continue to be in a certain condition', 'make a certain noise or sound', 'perform as expected when applied', 'to be spent or finished', 'progress by being changed', 'continue to live and avoid dying', 'pass, fare, or elapse; of a certain state of affairs or action', 'pass from physical life and lose all bodily attributes and functions necessary to sustain life', 'be in the right place or situation', 'be ranked or compare', 'begin or set in motion', \"have a turn; make one's move in a game\", 'be contained in', 'be sounded, played, or expressed', 'blend or harmonize', 'lead, extend, or afford access', 'be the right size or shape; fit correctly or as desired', \"go through in search of something; search through someone's belongings in an unauthorized way\", 'be spent', 'give support (to', 'stop operating or functioning'], 'Adjective': ['destroyed or killed', 'well in the past; former', 'stupefied or excited by a chemical substance (especially alcohol', 'drained of energy or effectiveness; extremely tired; completely exhausted', 'used up or no longer available']}\n",
      "{'Adjective': ['lacking in reality or substance or genuineness; not corresponding to acknowledged facts or criteria', 'not actually such; being or seeming fanciful or imaginary', 'contrived by art rather than nature', 'lacking material form or substance; unreal']}\n",
      "{'Adjective': ['having a higher than normal ceiling']}\n",
      "{'Adjective': ['not suitable for a particular occasion etc', 'not in keeping with what is correct or proper']}\n",
      "{'Noun': ['dense vegetation consisting of stunted trees or bushes', 'the act of cleaning a surface by rubbing it with a brush and soap and water'], 'Verb': ['clean with hard rubbing', 'wash thoroughly', 'postpone indefinitely or annul something that was scheduled'], 'Adjective': ['(of domestic animals']}\n",
      "{'Verb': ['put together out of artificial or natural components or parts', 'concoct something artificial or untrue', 'produce naturally', 'create or produce in a mechanical way'], 'Adjective': ['produced in a large-scale industrial operation']}\n",
      "{'Verb': ['come or bring to a finish or an end', 'finally be or do something', 'have an end, in a temporal, spatial, or quantitative sense; either spatial or metaphorical', 'provide with a finish', \"finish eating all the food on one's plate or on the table\", 'cause to finish a relationship with somebody'], 'Adjective': ['(of materials or goods', 'ended or brought to an end', '(of skills or the products of skills', 'having a surface coating or finish applied', 'brought to ruin']}\n",
      "{'Adjective': ['happening or arising without apparent external cause', 'said or done without having been planned or written in advance']}\n",
      "{'Verb': ['pierce with a pointed object; make a hole into', 'make by piercing', 'reduce or lessen the size or importance of', 'cause to lose air pressure or collapse by piercing', 'be pierced or punctured'], 'Adjective': ['having a hole cut through']}\n",
      "{'Adjective': ['showing regard for others in manners, speech, behavior, etc.', 'marked by refinement in taste and manners', 'not rude; marked by satisfactory (or especially minimal']}\n",
      "{'Adjective': ['marked by intense agitation or emotion']}\n",
      "{'Verb': ['put on special clothes to appear particularly appealing and attractive'], 'Adjective': ['dressed or clothed especially in fine attire; often used in combination']}\n",
      "{'Verb': ['be imminent or about to happen'], 'Adjective': ['close in time; about to occur']}\n",
      "{'Verb': ['perceive by a physical sensation, e.g., coming from the skin or muscles', 'detect some circumstance or entity automatically', 'become aware of not through the senses but instinctively', 'comprehend'], 'Adjective': ['detected by instinct or inference rather than by recognized perceptual cues']}\n",
      "{'Adjective': ['showing signs of wear and tear', 'mean and unworthy and despicable']}\n",
      "{'Verb': ['put into a certain place or abstract location', 'place somebody in a particular situation or location', 'assign a rank or rating to', 'assign a location to', 'to arrange for', 'intend (something', 'recognize as being; establish the identity of someone or something', 'assign to (a job or a home', 'locate', 'estimate', 'identify the location or place of', 'make an investment', 'assign to a station', 'finish second or better in a horse or dog race', 'sing a note with the correct pitch'], 'Adjective': ['situated in a particular spot or position', 'put in position in relation to other things']}\n",
      "{'Adjective': ['having or showing arrogant superiority to and disdain of those one views as unworthy', 'expressive of contempt']}\n",
      "{'Adjective': ['covered with caliche, a hard calcium-carbonate encrusted soil']}\n",
      "{'Noun': ['any plant or flower of the genus Oxalis', 'any of certain coarse weedy plants with long taproots, sometimes used as table greens or in folk medicine', 'East Indian sparsely prickly annual herb or perennial subshrub widely cultivated for its fleshy calyxes used in tarts and jelly and for its bast fiber', 'large sour-tasting arrowhead-shaped leaves used in salads and sauces', 'a horse of a brownish orange to light brown color'], 'Adjective': ['of a light brownish color']}\n",
      "{'Noun': ['the trait of lacking restraint or control; reckless freedom from inhibition or worry', 'a feeling of extreme emotional intensity'], 'Verb': ['forsake, leave behind', 'give up with the intent of never claiming again', 'leave behind empty; move out of', 'stop maintaining or insisting on; of ideas or claims', 'leave someone who needs or counts on you; leave in the lurch']}\n",
      "Time:  25.28765354799998\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for word in words_arr:\n",
    "    print(dictionary.meaning(word))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00534107 -0.05319485  0.04075286 ...  0.06393981 -0.03195943\n",
      "  -0.00142658]\n",
      " [ 0.03774285 -0.06795481  0.04782863 ... -0.06420389 -0.00722645\n",
      "  -0.00940532]\n",
      " [-0.00523109 -0.0426867   0.01691896 ...  0.03859418 -0.0511612\n",
      "  -0.0152916 ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(arr)\n",
    "print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words_arr)\n",
    "print(len(words_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)\n",
    "print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array to store word vectors\n",
    "\n",
    "#currently set to store top 1000 words as their 100 dimensional word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(12296, 300))\n",
    "\n",
    "x = np.array(ndmin=300)\n",
    "for i in range(len(x)):\n",
    "    x[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning = dictionary.meaning(\"word\", disable_errors=True)\n",
    "for pos in meaning:\n",
    "    defn = meaning[pos]\n",
    "    print(pos)\n",
    "    print(defn)\n",
    "    defn_words = defn[0].split()\n",
    "    print(defn_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary.meaning(\"quickly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaningsList = list(dictionary.meaning(\"test\").values())\n",
    "print(len(meaningsList))\n",
    "print(meaningsList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for removing punctuation and replacing it with whitespace\n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "    words = (doc.translate(translator)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
