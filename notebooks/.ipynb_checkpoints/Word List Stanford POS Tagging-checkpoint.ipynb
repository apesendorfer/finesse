{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "# cosine similarity of word vectors\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fasttext model\n",
    "\n",
    "model = fasttext.load_model(\"/Users/alex/result/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array to store word vectors\n",
    "\n",
    "#currently set to store 29153 words as their 100 dimensional word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(29153, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of words from combined TF-IDF analysis results\n",
    "\n",
    "f = open(\"word_list.txt\", \"r\")\n",
    "\n",
    "doc = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "#print(doc)\n",
    "\n",
    "words = doc.split(\", \")\n",
    "\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store word vectors for the 29153 words in numpy array\n",
    "\n",
    "for i in range(0, 29153):\n",
    "    arr[i] = model.get_word_vector(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts included in word list\n",
    "\n",
    "# gatsby, moby-dick, kerouac, gbg, invman, frankenstein\n",
    "\n",
    "txt1 = \"gatsby.txt\"\n",
    "txt2 = \"moby-dick.txt\"\n",
    "txt3 = \"kerouac.txt\"\n",
    "txt4 = \"gbg.txt\"\n",
    "txt5 = \"invman.txt\"\n",
    "txt6 = \"frankenstein.txt\"\n",
    "\n",
    "lst1 = [txt1, txt2, txt3, txt4, txt5, txt6]\n",
    "\n",
    "def concatenate(lst):\n",
    "    s = \"\"\n",
    "    for text in lst:\n",
    "        f = open(text, \"r\")\n",
    "        temp = f.read()\n",
    "        f.close()\n",
    "        s = s + temp\n",
    "    return s\n",
    "\n",
    "s = concatenate(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(txt1, \"r\")\n",
    "s = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of The Great Gatsby, by F. Scott Fitzgerald\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org. If you are not located in the United States, you\\nwill have to check the laws of the country where you are located before\\nusing this eBook.\\n\\nTitle: The Great Gatsby\\n\\nAuthor: F. Scott Fitzgerald\\n\\nRelease Date: January 17, 2021 [eBook #64317]\\n[Most recently updated: January 24 2021]\\n\\nLanguage: English\\n\\nCharacter set encoding: UTF-8\\n\\nProduced by: Alex Cabal for the Standard Ebooks project, based on a\\n             transcription produced for Project Gutenberg Australia.\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK THE GREAT GATSBY ***\\n\\n\\n\\t\\t\\t   The Great Gatsby\\n\\t\\t\\t\\t  by\\n\\t\\t\\t F. Scott Fitzgerald\\n\\n\\n                           Tab'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Great', 'Gatsby', 'by', 'F']\n",
      "ï»¿The Project Gutenberg eBook of The Great Gatsby by F Scott Fitzgerald This eBook is for the use of \n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "words1 = (s.translate(translator)).split()\n",
    "print(words1[0:10])\n",
    "str1 = \" \".join(words1)\n",
    "print(str1[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5085316"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = []\n",
    "\n",
    "# Tokenizer\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "location = 0\n",
    "while(location + 100000 < len(s)):\n",
    "    tokenized_text += list(parser.tokenize(s[location:location + 100000]))\n",
    "    location += 100000\n",
    "tokenized_text += list(parser.tokenize(s[location:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_text = []\n",
    "\n",
    "# POS Tagger\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "\n",
    "location = 0\n",
    "while(location + 15000 < len(tokenized_text)):\n",
    "    tagged_text += list(pos_tagger.tag(tokenized_text[location:location + 15000]))\n",
    "    location += 15000\n",
    "tagged_text += list(pos_tagger.tag(tokenized_text[location:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pabulum', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('reader', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('want', 'VB'),\n",
       " ('of', 'IN'),\n",
       " ('culture', 'NN'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('reported', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('rather', 'RB'),\n",
       " (\"''\", \"''\"),\n",
       " ('chatted', 'VBD'),\n",
       " (\"''\", \"''\"),\n",
       " ('about', 'IN'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('thousand-and-one', 'JJ'),\n",
       " ('items', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('knowledge', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('seem', 'VB'),\n",
       " (',', ','),\n",
       " ('moreover', 'RB'),\n",
       " (',', ','),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cleverer', 'JJR'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('writers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('poked', 'VBD'),\n",
       " ('fun', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Ziegenhalss', 'NNPS'),\n",
       " (',', ','),\n",
       " ('at', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('rate', 'NN'),\n",
       " (',', ','),\n",
       " ('contends', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('such', 'JJ'),\n",
       " ('pieces', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('so', 'RB'),\n",
       " ('incomprehensible', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('only', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('viewed', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('self-persiflage', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('part', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('authors', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Quite', 'RB'),\n",
       " ('possibly', 'RB'),\n",
       " ('these', 'DT'),\n",
       " ('manufactured', 'VBN'),\n",
       " ('articles', 'NNS'),\n",
       " ('do', 'VBP'),\n",
       " ('indeed', 'RB'),\n",
       " ('contain', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('quantity', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('irony', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('self-mockery', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('understood', 'VBN'),\n",
       " ('until', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('key', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('found', 'VBN'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('producers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('trivia', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('cases', 'NNS'),\n",
       " ('attached', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('staffs', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('newspapers', 'NNS'),\n",
       " (';', ':'),\n",
       " ('in', 'IN'),\n",
       " ('other', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " ('they', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('free-lance', 'JJ'),\n",
       " ('scriveners', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Frequently', 'RB'),\n",
       " ('they', 'PRP'),\n",
       " ('enjoyed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('high-sounding', 'JJ'),\n",
       " ('title', 'NN'),\n",
       " ('of', 'IN'),\n",
       " (\"''\", \"''\"),\n",
       " ('writer', 'NN'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('but', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('many', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('seem', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('belonged', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('scholar', 'NN'),\n",
       " ('class', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Quite', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('were', 'VBD'),\n",
       " ('celebrated', 'JJ'),\n",
       " ('university', 'NN'),\n",
       " ('professors', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('favorite', 'JJ'),\n",
       " ('subjects', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('such', 'JJ'),\n",
       " ('essays', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('anecdotes', 'NNS'),\n",
       " ('taken', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lives', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('correspondence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('famous', 'JJ'),\n",
       " ('men', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('women', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('bore', 'VBD'),\n",
       " ('such', 'JJ'),\n",
       " ('titles', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " (\"''\", \"''\"),\n",
       " ('Friedrich', 'NNP'),\n",
       " ('Nietzsche', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Women', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Fashions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('1870', 'CD'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('or', 'CC'),\n",
       " (\"''\", \"''\"),\n",
       " ('The', 'DT'),\n",
       " ('Composer', 'NN'),\n",
       " ('Rossini', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Favorite', 'NNP'),\n",
       " ('Dishes', 'NNPS'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('or', 'CC'),\n",
       " (\"''\", \"''\"),\n",
       " ('The', 'DT'),\n",
       " ('Role', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Lapdog', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Lives', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Great', 'JJ'),\n",
       " ('Courtesans', 'NNS'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('.', '.'),\n",
       " ('Another', 'DT'),\n",
       " ('popular', 'JJ'),\n",
       " ('type', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('article', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('historical', 'JJ'),\n",
       " ('background', 'NN'),\n",
       " ('piece', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('currently', 'RB'),\n",
       " ('being', 'VBG'),\n",
       " ('talked', 'VBN'),\n",
       " ('about', 'IN'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('well-to-do', 'JJ'),\n",
       " (',', ','),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " (\"''\", \"''\"),\n",
       " ('The', 'DT'),\n",
       " ('Dream', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Creating', 'VBG'),\n",
       " ('Gold', 'NNP'),\n",
       " ('Through', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Centuries', 'NNS'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('or', 'CC'),\n",
       " (\"''\", \"''\"),\n",
       " ('Physico-chemical', 'JJ'),\n",
       " ('Experiments', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Influencing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('Weather', 'NNP'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('and', 'CC'),\n",
       " ('hundreds', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('similar', 'JJ'),\n",
       " ('subjects', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('When', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('look', 'VBP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('titles', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('Ziegenhalss', 'NNP'),\n",
       " ('cites', 'VBZ'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('feel', 'VBP'),\n",
       " ('surprise', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('there', 'EX'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('people', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('devoured', 'VBD'),\n",
       " ('such', 'JJ'),\n",
       " ('chitchat', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('daily', 'JJ'),\n",
       " ('reading', 'NN'),\n",
       " (';', ':'),\n",
       " ('but', 'CC'),\n",
       " ('what', 'WP'),\n",
       " ('astonishes', 'VBZ'),\n",
       " ('us', 'PRP'),\n",
       " ('far', 'RB'),\n",
       " ('more', 'RBR'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('authors', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('repute', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('of', 'IN'),\n",
       " ('decent', 'JJ'),\n",
       " ('education', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('helped', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " (\"''\", \"''\"),\n",
       " ('service', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('this', 'DT'),\n",
       " ('gigantic', 'JJ'),\n",
       " ('consumption', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('empty', 'JJ'),\n",
       " ('whimsies', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Significantly', 'RB'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('service', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('expression', 'NN'),\n",
       " ('used', 'VBN'),\n",
       " (';', ':'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('also', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('denoting', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('relationship', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('man', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('machine', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('periods', 'NNS'),\n",
       " ('interviews', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('well-known', 'JJ'),\n",
       " ('personalities', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('current', 'JJ'),\n",
       " ('problems', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('particularly', 'RB'),\n",
       " ('popular', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Ziegenhalss', 'NN'),\n",
       " ('devotes', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('separate', 'JJ'),\n",
       " ('chapter', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('these', 'DT'),\n",
       " ('.', '.'),\n",
       " ('Noted', 'VBD'),\n",
       " ('chemists', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('piano', 'NN'),\n",
       " ('virtuosos', 'NNS'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('queried', 'VBN'),\n",
       " ('about', 'IN'),\n",
       " ('politics', 'NNS'),\n",
       " (',', ','),\n",
       " ('for', 'IN'),\n",
       " ('example', 'NN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('popular', 'JJ'),\n",
       " ('actors', 'NNS'),\n",
       " (',', ','),\n",
       " ('dancers', 'NNS'),\n",
       " (',', ','),\n",
       " ('gymnasts', 'NNS'),\n",
       " (',', ','),\n",
       " ('aviators', 'NNS'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('poets', 'NNS'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('drawn', 'VBN'),\n",
       " ('out', 'RP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('benefits', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('drawbacks', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('bachelor', 'NN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('presumptive', 'JJ'),\n",
       " ('causes', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('financial', 'JJ'),\n",
       " ('crises', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('.', '.'),\n",
       " ('All', 'PDT'),\n",
       " ('that', 'WDT'),\n",
       " ('mattered', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('pieces', 'NNS'),\n",
       " ('was', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('link', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('well-known', 'JJ'),\n",
       " ('name', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('subject', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('current', 'JJ'),\n",
       " ('topical', 'JJ'),\n",
       " ('interest', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('reader', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('consult', 'VB'),\n",
       " ('Ziegenhalss', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('truly', 'RB'),\n",
       " ('startling', 'JJ'),\n",
       " ('examples', 'NNS'),\n",
       " (';', ':'),\n",
       " ('he', 'PRP'),\n",
       " ('gives', 'VBZ'),\n",
       " ('hundreds', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('As', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('said', 'VBN'),\n",
       " (',', ','),\n",
       " ('no', 'DT'),\n",
       " ('doubt', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('goodly', 'JJ'),\n",
       " ('dash', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('irony', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('mixed', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('with', 'IN'),\n",
       " ('all', 'PDT'),\n",
       " ('this', 'DT'),\n",
       " ('busy', 'JJ'),\n",
       " ('productivity', 'NN'),\n",
       " (';', ':'),\n",
       " ('it', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('even', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('demonic', 'JJ'),\n",
       " ('irony', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('irony', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('desperation', 'NN'),\n",
       " ('--', ':'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('hard', 'JJ'),\n",
       " ('indeed', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('put', 'VB'),\n",
       " ('ourselves', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('place', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('so', 'IN'),\n",
       " ('that', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('truly', 'RB'),\n",
       " ('understand', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('majority', 'NN'),\n",
       " (',', ','),\n",
       " ('who', 'WP'),\n",
       " ('seem', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('strikingly', 'RB'),\n",
       " ('fond', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('reading', 'NN'),\n",
       " (',', ','),\n",
       " ('must', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('accepted', 'VBN'),\n",
       " ('all', 'PDT'),\n",
       " ('these', 'DT'),\n",
       " ('grotesque', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('credulous', 'JJ'),\n",
       " ('earnestness', 'NN'),\n",
       " ('.', '.'),\n",
       " ('If', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('famous', 'JJ'),\n",
       " ('painting', 'NN'),\n",
       " ('changed', 'VBD'),\n",
       " ('owners', 'NNS'),\n",
       " (',', ','),\n",
       " ('if', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('precious', 'JJ'),\n",
       " ('manuscript', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('sold', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('auction', 'NN'),\n",
       " (',', ','),\n",
       " ('if', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('old', 'JJ'),\n",
       " ('palace', 'NN'),\n",
       " ('burned', 'VBD'),\n",
       " ('down', 'RB'),\n",
       " (',', ','),\n",
       " ('if', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('bearer', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('aristocratic', 'JJ'),\n",
       " ('name', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('involved', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('scandal', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('readers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('feature', 'NN'),\n",
       " ('articles', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('once', 'RB'),\n",
       " ('learned', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('facts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('more', 'JJR'),\n",
       " (',', ','),\n",
       " ('on', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('next', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('latest', 'JJS'),\n",
       " ('they', 'PRP'),\n",
       " ('received', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('additional', 'JJ'),\n",
       " ('dose', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('anecdotal', 'JJ'),\n",
       " (',', ','),\n",
       " ('historical', 'JJ'),\n",
       " (',', ','),\n",
       " ('psychological', 'JJ'),\n",
       " (',', ','),\n",
       " ('erotic', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('other', 'JJ'),\n",
       " ('stuff', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('catchword', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('torrent', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('zealous', 'JJ'),\n",
       " ('scribbling', 'VBG'),\n",
       " ('poured', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('over', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('ephemeral', 'JJ'),\n",
       " ('incident', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('in', 'IN'),\n",
       " ('quality', 'NN'),\n",
       " (',', ','),\n",
       " ('assortment', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('phraseology', 'NN'),\n",
       " ('all', 'RB'),\n",
       " ('this', 'DT'),\n",
       " ('material', 'NN'),\n",
       " ('bore', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('mark', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('goods', 'NNS'),\n",
       " ('rapidly', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('irresponsibly', 'RB'),\n",
       " ('turned', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('.', '.'),\n",
       " ('Incidentally', 'RB'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('appear', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('certain', 'JJ'),\n",
       " ('games', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('were', 'VBD'),\n",
       " ('regular', 'JJ'),\n",
       " ('concomitants', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('feature', 'NN'),\n",
       " ('article', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('readers', 'NNS'),\n",
       " ('themselves', 'PRP'),\n",
       " ('took', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('active', 'JJ'),\n",
       " ('role', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('games', 'NNS'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('put', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('use', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('glut', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('information', 'NN'),\n",
       " ('fodder', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('disquisition', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('Ziegenhalss', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('curious', 'JJ'),\n",
       " ('subject', 'NN'),\n",
       " ('of', 'IN'),\n",
       " (\"''\", \"''\"),\n",
       " ('Crossword', 'NN'),\n",
       " ('Puzzles', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('describes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('phenomenon', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Thousands', 'NNS'),\n",
       " ('upon', 'IN'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('persons', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('majority', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('whom', 'WP'),\n",
       " ('did', 'VBD'),\n",
       " ('heavy', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('led', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('hard', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " (',', ','),\n",
       " ('spent', 'VBD'),\n",
       " ('their', 'PRP$'),\n",
       " ('leisure', 'NN'),\n",
       " ('hours', 'NNS'),\n",
       " ('sitting', 'VBG'),\n",
       " ('over', 'IN'),\n",
       " ('squares', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('crosses', 'NNS'),\n",
       " ('made', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('letters', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('alphabet', 'NN'),\n",
       " (',', ','),\n",
       " ('filling', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('gaps', 'NNS'),\n",
       " ('according', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('certain', 'JJ'),\n",
       " ('rules', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('let', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('be', 'VB'),\n",
       " ('wary', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('seeing', 'VBG'),\n",
       " ('only', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('absurd', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('insane', 'JJ'),\n",
       " ('aspect', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('let', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('abstain', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('ridiculing', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('childish', 'JJ'),\n",
       " ('puzzle', 'NN'),\n",
       " ('games', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('cultural', 'JJ'),\n",
       " ('feature', 'NN'),\n",
       " ('articles', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('by', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('means', 'NNS'),\n",
       " ('innocuous', 'JJ'),\n",
       " ('children', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('playful', 'JJ'),\n",
       " ('PhÃ¦acians', 'NNPS'),\n",
       " ('.', '.'),\n",
       " ('Rather', 'RB'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('dwelt', 'VBP'),\n",
       " ('anxiously', 'RB'),\n",
       " ('among', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " (',', ','),\n",
       " ('economic', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('moral', 'JJ'),\n",
       " ('ferments', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('earthquakes', 'NNS'),\n",
       " (',', ','),\n",
       " ('waged', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('frightful', 'JJ'),\n",
       " ('wars', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('civil', 'JJ'),\n",
       " ('wars', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('little', 'JJ'),\n",
       " ('cultural', 'JJ'),\n",
       " ('games', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('charming', 'JJ'),\n",
       " (',', ','),\n",
       " ('meaningless', 'JJ'),\n",
       " ('childishness', 'NN'),\n",
       " ('.', '.'),\n",
       " ('These', 'DT'),\n",
       " ('games', 'NNS'),\n",
       " ('sprang', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('deep', 'JJ'),\n",
       " ('need', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('close', 'VB'),\n",
       " ('their', 'PRP$'),\n",
       " ('eyes', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('flee', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('unsolved', 'JJ'),\n",
       " ('problems', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('anxious', 'JJ'),\n",
       " ('forebodings', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('doom', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('imaginary', 'JJ'),\n",
       " ('world', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('innocuous', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('possible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('assiduously', 'RB'),\n",
       " ('learned', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('drive', 'VB'),\n",
       " ('automobiles', 'NNS'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('play', 'VB'),\n",
       " ('difficult', 'JJ'),\n",
       " ('card', 'NN'),\n",
       " ('games', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('lose', 'VBP'),\n",
       " ('themselves', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('crossword', 'NN'),\n",
       " ('puzzles', 'NNS'),\n",
       " ('--', ':'),\n",
       " ('for', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('faced', 'VBD'),\n",
       " ('death', 'NN'),\n",
       " (',', ','),\n",
       " ('fear', 'NN'),\n",
       " (',', ','),\n",
       " ('pain', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('hunger', 'NN'),\n",
       " ('almost', 'RB'),\n",
       " ('without', 'IN'),\n",
       " ('defenses', 'NNS'),\n",
       " (',', ','),\n",
       " ('could', 'MD'),\n",
       " ('no', 'RB'),\n",
       " ('longer', 'RB'),\n",
       " ('accept', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('consolations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('churches', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('could', 'MD'),\n",
       " ('obtain', 'VB'),\n",
       " ('no', 'DT'),\n",
       " ('useful', 'JJ'),\n",
       " ('advice', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('Reason', 'NN'),\n",
       " ('.', '.'),\n",
       " ('These', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('read', 'VBP'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('articles', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('listened', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('lectures', 'VBZ'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('take', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('trouble', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('strengthen', 'VB'),\n",
       " ('themselves', 'PRP'),\n",
       " ('against', 'IN'),\n",
       " ('fear', 'NN'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('combat', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('dread', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('death', 'NN'),\n",
       " ('within', 'IN'),\n",
       " ('themselves', 'PRP'),\n",
       " (';', ':'),\n",
       " ('they', 'PRP'),\n",
       " ('moved', 'VBD'),\n",
       " ('spasmodically', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('through', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('had', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('belief', 'NN'),\n",
       " ('in', 'IN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text[550000:551000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keys = []\n",
    "pos_values = []\n",
    "for i in range(len(tagged_text)):\n",
    "    pos_keys.append(tagged_text[i][0])\n",
    "    pos_values.append(tagged_text[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Great', 'Gatsby', ',', 'by']\n",
      "['DT', 'NN', 'NNP', 'NNP', 'IN', 'DT', 'JJ', 'NNP', ',', 'IN']\n"
     ]
    }
   ],
   "source": [
    "print(pos_keys[0:10])\n",
    "print(pos_values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(len(pos_keys)):\n",
    "    if pos_keys[i] not in d:\n",
    "        d[pos_keys[i]] = [pos_values[i]]\n",
    "    else:\n",
    "        if pos_values[i] not in d[pos_keys[i]]:\n",
    "            d[pos_keys[i]].append(pos_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40727"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('How', 'WRB'), (\"'s\", 'POS'), ('your', 'PRP$'), ('family', 'NN'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "#from nltk.parse import CoreNLPParser\n",
    "\n",
    "# Tokenizer\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "text = list(parser.tokenize(\"How's are you?\"))\n",
    "\n",
    "# POS Tagger\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "print(list(pos_tagger.tag(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('fearless', 'JJ'), ('person', 'NN'), ('happily', 'RB'), ('walked', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('couch', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "input_sent = parser.tokenize(\"The fearless person happily walked to the couch.\")\n",
    "input_sent_pos = list(pos_tagger.tag(input_sent))\n",
    "print(input_sent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-02e914adcda3>:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.48691839599996456\n",
      "sofa\n",
      "bed\n",
      "settee\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ottoman'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-02e914adcda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput_sent_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ottoman'"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# user word\n",
    "word_index = 7\n",
    "user_word = input_sent_pos[word_index][0]\n",
    "\n",
    "user_word_vec = model.get_word_vector(user_word)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# iterate through numpy array and find vectors that meet a threshold for cosine similarity\n",
    "cos_sim = 0.4\n",
    "for i in range(0, 29153):\n",
    "    current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n",
    "    if current > cos_sim and words[i] != user_word and user_word[0:2] != words[i][0:2] and user_word[0:3] not in words[i]:\n",
    "        results[words[i]] = current\n",
    "        \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "# dictionary: results\n",
    "sorted_values = sorted(results.values(), reverse = True) # Sort the values\n",
    "sorted_dict = {}\n",
    "\n",
    "for i in sorted_values:\n",
    "    for k in results.keys():\n",
    "        if results[k] == i:\n",
    "            sorted_dict[k] = results[k]\n",
    "            break\n",
    "\n",
    "#print(sorted_dict)\n",
    "count = 0\n",
    "for key in sorted_dict:\n",
    "    if input_sent_pos[word_index][1] in d[key]:\n",
    "        print(key)\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fearless\n",
    "Time:  0.5343051189997823\n",
    "courageous\n",
    "dauntless\n",
    "daring\n",
    "indomitable\n",
    "intrepid\n",
    "\n",
    "### happily\n",
    "Time:  0.47796867699980794\n",
    "contentedly\n",
    "joyfully\n",
    "gladly\n",
    "cheerfully\n",
    "joyously\n",
    "\n",
    "\n",
    "### walked\n",
    "Time:  0.4823025589998906\n",
    "strolled\n",
    "sauntered\n",
    "ambled\n",
    "strode\n",
    "trudged\n",
    "\n",
    "### couch\n",
    "Time:  0.48691839599996456\n",
    "sofa\n",
    "bed\n",
    "settee\n",
    "KeyError: 'ottoman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = set(words)\n",
    "lst2 = set(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29153"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40727"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate the intersection\n",
    "# of two lists using set() method\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "lst3 = intersection(lst1, lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25322"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ottoman\" in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ottoman\" in d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eased looking at Daisy, and I think he revalued\n",
      "everything in his house accordin\n",
      "n this world,\n",
      "head winds are far more prevalent than winds from astern (that is,\n",
      "unters revived the\n",
      "glories of those primeval times when Adam walked majestic as \n",
      " breasts of women in popular magazines;\n",
      "evaluating the hardness of the steel hal\n",
      "othilling to the plain and where in primeval times soft\n",
      "waves must have washed f\n",
      "y must be in their\n",
      "private concerns and evaluations and wishes!\" Dean drove on w\n",
      "self, it'll be about Ragusa, a late medieval maritime city state republic which \n",
      " already on the verge of that dreadful\n",
      "devaluation of the Word which produced, a\n",
      "e life of the\n",
      "mind, appear dubious and devalued and in which we tend to envy\n",
      "eve\n",
      "echt encountered it, had already been prevalent at that time,\n",
      "for one day Elder \n",
      "l possessing an enormous library of medieval theology, it had\n",
      "risen to new glory\n",
      "nd can prevent\n",
      "is the discrediting and devaluation of the Game in its own home,\n",
      "\n",
      "the conflict of\n",
      "interests threatens to devalue, distort, and do violence to trut\n",
      "stomed as the\n",
      "youth was to the manner prevalent among these masters of\n",
      "meditatio\n",
      "nd and useful up to the moment you last evaluated them.\n",
      "Is that asking too much \n",
      "ingered in this horror a remnant of\n",
      "primeval, pre-Christian, ancient pagan knowl\n",
      "th reflected the\n",
      "neo-romanticism then prevalent among many writers of his\n",
      "genera\n",
      "ent state and the\n",
      "process of psychic re-evaluation. Hesse came to the conclusion\n",
      "e is\n",
      "doomed to brutishness reflects a prevalent contemporary concern:\n",
      "our comput\n",
      "is the gift of its individuals who see, evaluate, record . . . We create the\n",
      "rac\n",
      "ow hide the bleeding wound!\"\n",
      "\"Don't overevaluate it,\" Jack said, quieter now. \"T\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(s) - 10):\n",
    "    if (s[i] == \"E\" or s[i] == \"e\") and s[i+1] == \"v\" and s[i+2] == \"a\" and s[i+3] == \"l\":\n",
    "        print(s[i-40:i+40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import timeit\n",
    "\n",
    "#start = timeit.default_timer()\n",
    "\n",
    "# user word\n",
    "\n",
    "def sentence_suggestions(input_sent):\n",
    "    parser = CoreNLPParser(url='http://localhost:9000')\n",
    "    input_sent = parser.tokenize(input_sent)\n",
    "    pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "    input_sent_pos = list(pos_tagger.tag(input_sent))\n",
    "    \n",
    "    for word_index in range(len(input_sent_pos)):\n",
    "        \n",
    "        user_word = input_sent_pos[word_index][0]\n",
    "        print(\"Word: \" + user_word + \" POS: \" + input_sent_pos[word_index][1])\n",
    "\n",
    "        user_word_vec = model.get_word_vector(user_word)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # iterate through numpy array and find vectors that meet a threshold for cosine similarity\n",
    "        cos_sim = 0.4\n",
    "        for i in range(0, 29153):\n",
    "            current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n",
    "            if current > cos_sim and words[i] != user_word and user_word[0:2] != words[i][0:2] and user_word[0:3] not in words[i]:\n",
    "                results[words[i]] = current\n",
    "\n",
    "        #stop = timeit.default_timer()\n",
    "\n",
    "        #print('Time: ', stop - start)\n",
    "\n",
    "        # dictionary: results\n",
    "        sorted_values = sorted(results.values(), reverse = True) # Sort the values\n",
    "        sorted_dict = {}\n",
    "\n",
    "        for i in sorted_values:\n",
    "            for k in results.keys():\n",
    "                if results[k] == i:\n",
    "                    sorted_dict[k] = results[k]\n",
    "                    break\n",
    "\n",
    "        #print(sorted_dict)\n",
    "        count = 0\n",
    "        for key in sorted_dict:\n",
    "            try:\n",
    "                if input_sent_pos[word_index][1] in d[key]:\n",
    "                    print(key)\n",
    "                    count += 1\n",
    "                if count == 5:\n",
    "                    break\n",
    "            except:\n",
    "                print(\"ERROR: pos dictionary\")\n",
    "                \n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: We\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-518866a1aa6d>:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us\n",
      "---\n",
      "Word: are\n",
      "seem\n",
      "need\n",
      "appear\n",
      "exist\n",
      "abound\n",
      "---\n",
      "Word: testing\n",
      "ERROR: pos dictionary\n",
      "evaluating\n",
      "ERROR: pos dictionary\n",
      "training\n",
      "fuzzing\n",
      "conducting\n",
      "experimenting\n",
      "---\n",
      "Word: our\n",
      "---\n",
      "Word: wonderful\n",
      "fantastic\n",
      "lovely\n",
      "fabulous\n",
      "marvelous\n",
      "amazing\n",
      "---\n",
      "Word: new\n",
      "exciting\n",
      "fresh\n",
      "old\n",
      "snazzy\n",
      "promising\n",
      "---\n",
      "Word: program\n",
      "initiative\n",
      "curriculum\n",
      "training\n",
      "seminar\n",
      "facility\n",
      "---\n",
      "Word: !\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "sentence_suggestions(\"We are testing our wonderful new program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"we\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VB', 'VBP']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"seem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"evaluation\" in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"re-evaluation\" in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"re\" in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['completed', 'his', 'disillusionment', 'with', 'his', 'present', 'state', 'and', 'the', 'process', 'of', 'psychic', 're-evaluation', '.', 'Hesse', 'came', 'to', 'the', 'conclusion', 'that']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokenized_text)):\n",
    "    if tokenized_text[i] == \"of\" and tokenized_text[i+1] == \"psychic\":\n",
    "        print(tokenized_text[i-10:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Tokarczuk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-518866a1aa6d>:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Word: postulates\n",
      "argues\n",
      "contradicts\n",
      "suggests\n",
      "contends\n",
      "underlies\n",
      "---\n",
      "Word: the\n",
      "every\n",
      "half\n",
      "---\n",
      "Word: book\n",
      "novel\n",
      "author\n",
      "ERROR: pos dictionary\n",
      "read\n",
      "chapter\n",
      "autobiography\n",
      "---\n",
      "Word: 's\n",
      "---\n",
      "Word: ambiguous\n",
      "vague\n",
      "confusing\n",
      "contradictory\n",
      "unclear\n",
      "nebulous\n",
      "---\n",
      "Word: and\n",
      "---\n",
      "Word: fluid\n",
      "osmotic\n",
      "bodily\n",
      "---\n",
      "Word: nature\n",
      "essence\n",
      "wildness\n",
      "beauty\n",
      "mutability\n",
      "sacredness\n",
      "---\n",
      "Word: in\n",
      "near\n",
      "around\n",
      "---\n",
      "Word: the\n",
      "every\n",
      "half\n",
      "---\n",
      "Word: few\n",
      "several\n",
      "many\n",
      "countless\n",
      "little\n",
      "plenty\n",
      "---\n",
      "Word: first\n",
      "second\n",
      "third\n",
      "last\n",
      "next\n",
      "seventh\n",
      "---\n",
      "Word: pages\n",
      "chapters\n",
      "links\n",
      "ERROR: pos dictionary\n",
      "biographies\n",
      "sections\n",
      "illustrations\n",
      "---\n",
      "Word: ,\n",
      "---\n",
      "Word: developing\n",
      "creating\n",
      "improving\n",
      "establishing\n",
      "adapting\n",
      "acquiring\n",
      "---\n",
      "Word: a\n",
      "---\n",
      "Word: narrator\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "heroine\n",
      "author\n",
      "reader\n",
      "listener\n",
      "writer\n",
      "---\n",
      "Word: with\n",
      "along\n",
      "alongside\n",
      "despite\n",
      "amidst\n",
      "amid\n",
      "---\n",
      "Word: a\n",
      "---\n",
      "Word: yearning\n",
      "longing\n",
      "desire\n",
      "hankering\n",
      "craving\n",
      "wistfulness\n",
      "---\n",
      "Word: for\n",
      "besides\n",
      "except\n",
      "---\n",
      "Word: the\n",
      "every\n",
      "half\n",
      "---\n",
      "Word: past\n",
      "decade\n",
      "year\n",
      "week\n",
      "time\n",
      "month\n",
      "---\n",
      "Word: ,\n",
      "---\n",
      "Word: present\n",
      "past\n",
      "future\n",
      "given\n",
      "---\n",
      "Word: ,\n",
      "---\n",
      "Word: and\n",
      "---\n",
      "Word: future\n",
      "potential\n",
      "possibility\n",
      "past\n",
      "promise\n",
      "fruition\n",
      "---\n",
      "Word: .\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "sentence_suggestions(\"Tokarczuk postulates the bookâs ambiguous and fluid nature in the few first pages, developing a narrator with a yearning for the past, present, and future.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: While POS: IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-121-6aa3b574028c>:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  current = dot(user_word_vec, arr[i]) / (norm(user_word_vec) * norm(arr[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "although\n",
      "though\n",
      "whereas\n",
      "despite\n",
      "whilst\n",
      "---\n",
      "Word: most POS: JJS\n",
      "easiest\n",
      "simplest\n",
      "best\n",
      "finest\n",
      "rarest\n",
      "---\n",
      "Word: child POS: NN\n",
      "infant\n",
      "mother\n",
      "kid\n",
      "daughter\n",
      "baby\n",
      "---\n",
      "Word: narrators POS: NNS\n",
      "protagonists\n",
      "voices\n",
      "actors\n",
      "monologues\n",
      "singers\n",
      "---\n",
      "Word: in POS: IN\n",
      "near\n",
      "around\n",
      "---\n",
      "Word: literature POS: NN\n",
      "historiography\n",
      "poetry\n",
      "fiction\n",
      "philology\n",
      "folklore\n",
      "---\n",
      "Word: speak POS: VBP\n",
      "converse\n",
      "hear\n",
      "listen\n",
      "tell\n",
      "ask\n",
      "---\n",
      "Word: in POS: IN\n",
      "near\n",
      "around\n",
      "---\n",
      "Word: the POS: DT\n",
      "every\n",
      "half\n",
      "---\n",
      "Word: present POS: JJ\n",
      "past\n",
      "future\n",
      "given\n",
      "---\n",
      "Word: tense POS: JJ\n",
      "uneasy\n",
      "nervy\n",
      "taut\n",
      "uncomfortable\n",
      "unnerving\n",
      "---\n",
      "Word: and POS: CC\n",
      "---\n",
      "Word: offer POS: NN\n",
      "opportunity\n",
      "avail\n",
      "discount\n",
      "refuse\n",
      "invitation\n",
      "---\n",
      "Word: unique POS: JJ\n",
      "exceptional\n",
      "peculiar\n",
      "remarkable\n",
      "incredible\n",
      "extraordinary\n",
      "---\n",
      "Word: insight POS: NN\n",
      "understanding\n",
      "glimpse\n",
      "perspective\n",
      "knowledge\n",
      "wisdom\n",
      "---\n",
      "Word: -- POS: :\n",
      "---\n",
      "Word: often POS: RB\n",
      "frequently\n",
      "sometimes\n",
      "rarely\n",
      "seldom\n",
      "occasionally\n",
      "---\n",
      "Word: beyond POS: IN\n",
      "within\n",
      "outside\n",
      "without\n",
      "---\n",
      "Word: the POS: DT\n",
      "every\n",
      "half\n",
      "---\n",
      "Word: scope POS: NN\n",
      "purview\n",
      "breadth\n",
      "extent\n",
      "comprehensiveness\n",
      "context\n",
      "---\n",
      "Word: of POS: IN\n",
      "---\n",
      "Word: what POS: WP\n",
      "---\n",
      "Word: one POS: PRP\n",
      "---\n",
      "Word: would POS: MD\n",
      "could\n",
      "might\n",
      "may\n",
      "ought\n",
      "must\n",
      "---\n",
      "Word: expect POS: VB\n",
      "anticipate\n",
      "want\n",
      "know\n",
      "think\n",
      "say\n",
      "---\n",
      "Word: from POS: IN\n",
      "across\n",
      "outside\n",
      "onto\n",
      "within\n",
      "along\n",
      "---\n",
      "Word: a POS: DT\n",
      "---\n",
      "Word: child POS: NN\n",
      "infant\n",
      "mother\n",
      "kid\n",
      "daughter\n",
      "baby\n",
      "---\n",
      "Word: -- POS: :\n",
      "---\n",
      "Word: Tokarczuk POS: NNP\n",
      "---\n",
      "Word: 's POS: POS\n",
      "---\n",
      "Word: narrator POS: NN\n",
      "ERROR: pos dictionary\n",
      "ERROR: pos dictionary\n",
      "heroine\n",
      "author\n",
      "reader\n",
      "listener\n",
      "writer\n",
      "---\n",
      "Word: is POS: VBZ\n",
      "represents\n",
      "means\n",
      "seems\n",
      "makes\n",
      "appears\n",
      "---\n",
      "Word: different POS: JJ\n",
      "various\n",
      "varied\n",
      "several\n",
      "many\n",
      "identical\n",
      "---\n",
      "Word: . POS: .\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "sentence_suggestions(\"While most child narrators in literature speak in the present tense and offer unique insight â often beyond the scope of what one would expect from a child â Tokarczukâs narrator is different.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
