{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "# cosine similarity of word vectors\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fasttext model\n",
    "\n",
    "model = fasttext.load_model(\"/Users/alex/result/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array to store word vectors\n",
    "\n",
    "#currently set to store 29153 words as their 100 dimensional word vectors\n",
    "\n",
    "arr = np.ndarray(shape=(29153, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of words from combined TF-IDF analysis results\n",
    "\n",
    "f = open(\"word_list.txt\", \"r\")\n",
    "\n",
    "doc = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "#print(doc)\n",
    "\n",
    "words = doc.split(\", \")\n",
    "\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store word vectors for the 29153 words in numpy array\n",
    "\n",
    "for i in range(0, 29153):\n",
    "    arr[i] = model.get_word_vector(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts included in word list\n",
    "\n",
    "# gatsby, moby-dick, kerouac, gbg, invman, frankenstein\n",
    "\n",
    "txt1 = \"gatsby.txt\"\n",
    "txt2 = \"moby-dick.txt\"\n",
    "txt3 = \"kerouac.txt\"\n",
    "txt4 = \"gbg.txt\"\n",
    "txt5 = \"invman.txt\"\n",
    "txt6 = \"frankenstein.txt\"\n",
    "\n",
    "lst1 = [txt1, txt2, txt3, txt4, txt5, txt6]\n",
    "\n",
    "def concatenate(lst):\n",
    "    s = \"\"\n",
    "    for text in lst:\n",
    "        f = open(text, \"r\")\n",
    "        temp = f.read()\n",
    "        f.close()\n",
    "        s = s + temp\n",
    "    return s\n",
    "\n",
    "s = concatenate(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(txt1, \"r\")\n",
    "s = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of The Great Gatsby, by F. Scott Fitzgerald\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org. If you are not located in the United States, you\\nwill have to check the laws of the country where you are located before\\nusing this eBook.\\n\\nTitle: The Great Gatsby\\n\\nAuthor: F. Scott Fitzgerald\\n\\nRelease Date: January 17, 2021 [eBook #64317]\\n[Most recently updated: January 24 2021]\\n\\nLanguage: English\\n\\nCharacter set encoding: UTF-8\\n\\nProduced by: Alex Cabal for the Standard Ebooks project, based on a\\n             transcription produced for Project Gutenberg Australia.\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK THE GREAT GATSBY ***\\n\\n\\n\\t\\t\\t   The Great Gatsby\\n\\t\\t\\t\\t  by\\n\\t\\t\\t F. Scott Fitzgerald\\n\\n\\n                           Tab'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Great', 'Gatsby', 'by', 'F']\n",
      "ï»¿The Project Gutenberg eBook of The Great Gatsby by F Scott Fitzgerald This eBook is for the use of \n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "words1 = (s.translate(translator)).split()\n",
    "print(words1[0:10])\n",
    "str1 = \" \".join(words1)\n",
    "print(str1[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-54fbc268ae59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoreNLPParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://localhost:9000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mdefault_properties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, data, properties, timeout)\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "list(parser.tokenize(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.parse import CoreNLPParser\n",
    "\n",
    "# Tokenizer\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "list(parser.tokenize('What is the airspeed of an unladen swallow?'))\n",
    "\n",
    "# POS Tagger\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "list(pos_tagger.tag('What is the airspeed of an unladen swallow ?'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
