{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.0.1-cp38-cp38-macosx_10_9_x86_64.whl (23.9 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/alex/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/alex/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.1.0\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "!python -m pip install -U gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONCE\n",
    "#\n",
    "#\n",
    "#\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/alex/result/cc.en.300.vec')\n",
    "similar = model.most_similar(positive=['man'],topn=10)\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"/Users/alex/result/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'the',\n",
       " '.',\n",
       " 'and',\n",
       " 'to',\n",
       " 'of',\n",
       " 'a',\n",
       " '</s>',\n",
       " 'in',\n",
       " 'is',\n",
       " ':',\n",
       " 'I',\n",
       " 'for',\n",
       " 'that',\n",
       " ')',\n",
       " '\"',\n",
       " '(',\n",
       " 'on',\n",
       " 'with',\n",
       " 'it',\n",
       " 'you',\n",
       " 'The',\n",
       " 'was',\n",
       " 'as',\n",
       " 'are',\n",
       " 'at',\n",
       " '/',\n",
       " '’',\n",
       " 'be',\n",
       " 'by',\n",
       " \"'s\",\n",
       " 'this',\n",
       " 'have',\n",
       " 'from',\n",
       " 'or',\n",
       " '!',\n",
       " 'not',\n",
       " 'your',\n",
       " 'an',\n",
       " \"'\",\n",
       " 'but',\n",
       " '?',\n",
       " 'can',\n",
       " '-',\n",
       " 'will',\n",
       " 's',\n",
       " 'my',\n",
       " 'has',\n",
       " 'all',\n",
       " 'we',\n",
       " 'they',\n",
       " 'he',\n",
       " 'his',\n",
       " 'more',\n",
       " 'one',\n",
       " 'about',\n",
       " 'their',\n",
       " \"'t\",\n",
       " 'so',\n",
       " 'which',\n",
       " 'It',\n",
       " 'out',\n",
       " 'up',\n",
       " '...',\n",
       " 'were',\n",
       " 'had',\n",
       " 'who',\n",
       " 'like',\n",
       " ';',\n",
       " '“',\n",
       " 'our',\n",
       " 'would',\n",
       " '”',\n",
       " 'time',\n",
       " 'been',\n",
       " 'if',\n",
       " 'also',\n",
       " 'just',\n",
       " 'when',\n",
       " 'her',\n",
       " 'This',\n",
       " 'me',\n",
       " 'there',\n",
       " 'do',\n",
       " 'what',\n",
       " 'some',\n",
       " 'other',\n",
       " 'In',\n",
       " 'them',\n",
       " '–',\n",
       " '1',\n",
       " 'get',\n",
       " 'new',\n",
       " 'into',\n",
       " '&',\n",
       " 'We',\n",
       " 'than',\n",
       " 'A',\n",
       " 'no',\n",
       " 'only',\n",
       " 'first',\n",
       " 'any',\n",
       " 'its',\n",
       " 'people',\n",
       " '2',\n",
       " '$',\n",
       " 'very',\n",
       " 't',\n",
       " 'over',\n",
       " 'she',\n",
       " '%',\n",
       " 'how',\n",
       " 'make',\n",
       " 'You',\n",
       " 'said',\n",
       " 'He',\n",
       " 'two',\n",
       " 'may',\n",
       " 'know',\n",
       " 'then',\n",
       " 'see',\n",
       " 'after',\n",
       " 'most',\n",
       " 'good',\n",
       " 'years',\n",
       " 'If',\n",
       " 'these',\n",
       " 'now',\n",
       " '3',\n",
       " 'use',\n",
       " 'because',\n",
       " 'well',\n",
       " 'work',\n",
       " 'could',\n",
       " 'us',\n",
       " 'don',\n",
       " 'way',\n",
       " 'much',\n",
       " 'back',\n",
       " 'many',\n",
       " 'think',\n",
       " 'where',\n",
       " 'even',\n",
       " 'him',\n",
       " 'through',\n",
       " 'am',\n",
       " '10',\n",
       " '|',\n",
       " 'here',\n",
       " '#',\n",
       " 'made',\n",
       " 'year',\n",
       " 'should',\n",
       " '*',\n",
       " 'really',\n",
       " 'being',\n",
       " 'such',\n",
       " 'need',\n",
       " 'great',\n",
       " 'And',\n",
       " ']',\n",
       " '4',\n",
       " '[',\n",
       " '5',\n",
       " 'day',\n",
       " 'before',\n",
       " 'want',\n",
       " 'used',\n",
       " 'go',\n",
       " 'those',\n",
       " '…',\n",
       " 'But',\n",
       " 'right',\n",
       " \"'m\",\n",
       " 'take',\n",
       " '—',\n",
       " 'May',\n",
       " 'still',\n",
       " 'last',\n",
       " 'off',\n",
       " 'too',\n",
       " 'New',\n",
       " 'going',\n",
       " 'best',\n",
       " 'find',\n",
       " 'love',\n",
       " 'did',\n",
       " 'while',\n",
       " 'home',\n",
       " 'There',\n",
       " 'They',\n",
       " 'same',\n",
       " 'around',\n",
       " 'help',\n",
       " 'down',\n",
       " 'information',\n",
       " 'UTC',\n",
       " 'place',\n",
       " 'i',\n",
       " '2017',\n",
       " 'For',\n",
       " 'little',\n",
       " 'life',\n",
       " 'between',\n",
       " 'each',\n",
       " 'own',\n",
       " 'both',\n",
       " '12',\n",
       " '6',\n",
       " 'world',\n",
       " 'part',\n",
       " 'few',\n",
       " '8',\n",
       " '7',\n",
       " 'talk',\n",
       " 'As',\n",
       " 'look',\n",
       " '2012',\n",
       " 'things',\n",
       " '11',\n",
       " 'say',\n",
       " 'does',\n",
       " 'every',\n",
       " 'something',\n",
       " '2013',\n",
       " 'during',\n",
       " 'got',\n",
       " 'So',\n",
       " \"'ve\",\n",
       " 'What',\n",
       " 'since',\n",
       " 'found',\n",
       " 'long',\n",
       " 'different',\n",
       " 'says',\n",
       " '>',\n",
       " 'never',\n",
       " 'another',\n",
       " '�',\n",
       " 'Ã',\n",
       " 'better',\n",
       " '2016',\n",
       " 'using',\n",
       " '+',\n",
       " 'free',\n",
       " '20',\n",
       " 'under',\n",
       " 'three',\n",
       " 'family',\n",
       " 'She',\n",
       " 'including',\n",
       " 'That',\n",
       " 'always',\n",
       " '\\\\',\n",
       " 'next',\n",
       " 'come',\n",
       " 'without',\n",
       " 'My',\n",
       " 'again',\n",
       " '9',\n",
       " 'game',\n",
       " \"'re\",\n",
       " '15',\n",
       " '2011',\n",
       " 'When',\n",
       " 'days',\n",
       " 'set',\n",
       " '30',\n",
       " 'All',\n",
       " 'number',\n",
       " '2014',\n",
       " 'end',\n",
       " 'lot',\n",
       " 'business',\n",
       " 'sure',\n",
       " 'system',\n",
       " 'book',\n",
       " '2015',\n",
       " 'against',\n",
       " 'high',\n",
       " '=',\n",
       " '2010',\n",
       " 'must',\n",
       " 'available',\n",
       " 'To',\n",
       " 'might',\n",
       " 'show',\n",
       " 'area',\n",
       " 'Â',\n",
       " 'week',\n",
       " '00',\n",
       " 'away',\n",
       " 'team',\n",
       " 'March',\n",
       " 'name',\n",
       " 'until',\n",
       " 'April',\n",
       " 'give',\n",
       " 'thing',\n",
       " 'read',\n",
       " 'put',\n",
       " \"'ll\",\n",
       " 'On',\n",
       " 'small',\n",
       " 'school',\n",
       " 'feel',\n",
       " 'second',\n",
       " 'company',\n",
       " 'June',\n",
       " 'old',\n",
       " 'didn',\n",
       " 'page',\n",
       " 'keep',\n",
       " 'top',\n",
       " 'why',\n",
       " 'January',\n",
       " 'site',\n",
       " '18',\n",
       " 'post',\n",
       " 'today',\n",
       " '16',\n",
       " 'within',\n",
       " '0',\n",
       " 'service',\n",
       " 'having',\n",
       " 'looking',\n",
       " 'American',\n",
       " 'point',\n",
       " 'data',\n",
       " 'though',\n",
       " '½',\n",
       " 'July',\n",
       " 'University',\n",
       " 'full',\n",
       " '14',\n",
       " 'm',\n",
       " 'able',\n",
       " 'left',\n",
       " 'With',\n",
       " 'support',\n",
       " 'United',\n",
       " '2009',\n",
       " '13',\n",
       " 'experience',\n",
       " 'room',\n",
       " '¿',\n",
       " 'water',\n",
       " 'state',\n",
       " '‘',\n",
       " 'big',\n",
       " 'order',\n",
       " 'October',\n",
       " 'No',\n",
       " 'article',\n",
       " 'case',\n",
       " 'making',\n",
       " 'enough',\n",
       " 'ago',\n",
       " 'house',\n",
       " 'September',\n",
       " '17',\n",
       " 'children',\n",
       " 'One',\n",
       " 'local',\n",
       " 'December',\n",
       " 'start',\n",
       " 'times',\n",
       " 'February',\n",
       " 'called',\n",
       " 'August',\n",
       " '25',\n",
       " 'November',\n",
       " 'ever',\n",
       " 'More',\n",
       " '2008',\n",
       " 'done',\n",
       " 'change',\n",
       " 'play',\n",
       " 'group',\n",
       " 'working',\n",
       " 'based',\n",
       " 'online',\n",
       " 'http',\n",
       " 'course',\n",
       " 'least',\n",
       " 'doesn',\n",
       " 'money',\n",
       " 'won',\n",
       " 'man',\n",
       " 'less',\n",
       " '@',\n",
       " 'important',\n",
       " 'After',\n",
       " '24',\n",
       " 'How',\n",
       " '22',\n",
       " 'try',\n",
       " 'getting',\n",
       " 'thought',\n",
       " 'public',\n",
       " 'actually',\n",
       " 'already',\n",
       " 'night',\n",
       " 'person',\n",
       " 're',\n",
       " '21',\n",
       " 'went',\n",
       " '..',\n",
       " 'story',\n",
       " 'several',\n",
       " '--',\n",
       " 'later',\n",
       " 'makes',\n",
       " 'side',\n",
       " 'list',\n",
       " 'following',\n",
       " '19',\n",
       " 'came',\n",
       " 'By',\n",
       " 'doing',\n",
       " 'power',\n",
       " 'large',\n",
       " 'season',\n",
       " 'provide',\n",
       " 'website',\n",
       " 'bit',\n",
       " 'far',\n",
       " 'real',\n",
       " 'known',\n",
       " 'took',\n",
       " 'PM',\n",
       " 'city',\n",
       " '23',\n",
       " 'let',\n",
       " 'At',\n",
       " 'along',\n",
       " 'together',\n",
       " 'per',\n",
       " '}',\n",
       " 'often',\n",
       " 'These',\n",
       " 'music',\n",
       " 'hard',\n",
       " 'God',\n",
       " 'share',\n",
       " 'Your',\n",
       " 'Our',\n",
       " 'line',\n",
       " 'process',\n",
       " 'care',\n",
       " 'others',\n",
       " 'open',\n",
       " 'John',\n",
       " 'car',\n",
       " 'services',\n",
       " 'include',\n",
       " 'food',\n",
       " 'started',\n",
       " 'easy',\n",
       " 'country',\n",
       " 'months',\n",
       " 'fact',\n",
       " 'women',\n",
       " 'yet',\n",
       " 'students',\n",
       " '2007',\n",
       " 'someone',\n",
       " 'once',\n",
       " 'live',\n",
       " 'problem',\n",
       " 'run',\n",
       " 'video',\n",
       " 've',\n",
       " 'become',\n",
       " 'government',\n",
       " 'everything',\n",
       " 'series',\n",
       " 'However',\n",
       " 'anything',\n",
       " 'four',\n",
       " 'pm',\n",
       " 'means',\n",
       " 'stay',\n",
       " '100',\n",
       " 'early',\n",
       " 'possible',\n",
       " 'past',\n",
       " 'design',\n",
       " 'quality',\n",
       " 'City',\n",
       " 'seen',\n",
       " 'States',\n",
       " 'given',\n",
       " 'pretty',\n",
       " 'State',\n",
       " 'blog',\n",
       " 'U.S.',\n",
       " \"'d\",\n",
       " 'film',\n",
       " 'nice',\n",
       " 'history',\n",
       " 'job',\n",
       " 'call',\n",
       " 'Now',\n",
       " 'kind',\n",
       " 'believe',\n",
       " 'community',\n",
       " 'needs',\n",
       " 'level',\n",
       " 'program',\n",
       " 'body',\n",
       " 'view',\n",
       " 'friends',\n",
       " 'control',\n",
       " 'comes',\n",
       " 'York',\n",
       " 'products',\n",
       " 'form',\n",
       " 'above',\n",
       " '26',\n",
       " 'School',\n",
       " 'health',\n",
       " 'minutes',\n",
       " 'probably',\n",
       " 'World',\n",
       " 'hours',\n",
       " 'fun',\n",
       " 'National',\n",
       " 'US',\n",
       " 'either',\n",
       " 'County',\n",
       " 'head',\n",
       " '28',\n",
       " 'example',\n",
       " 'product',\n",
       " 'please',\n",
       " 'close',\n",
       " 'beautiful',\n",
       " 'market',\n",
       " 'across',\n",
       " 'whole',\n",
       " 'offer',\n",
       " 'quite',\n",
       " 'trying',\n",
       " 'price',\n",
       " 'told',\n",
       " 'idea',\n",
       " 'members',\n",
       " 'light',\n",
       " '27',\n",
       " 'million',\n",
       " 'single',\n",
       " 'His',\n",
       " 'perfect',\n",
       " 'Please',\n",
       " 'hope',\n",
       " 'access',\n",
       " 'research',\n",
       " 'due',\n",
       " '2006',\n",
       " 'tell',\n",
       " 'seems',\n",
       " 'South',\n",
       " 'added',\n",
       " 'almost',\n",
       " 'current',\n",
       " 'short',\n",
       " 'bad',\n",
       " 'Not',\n",
       " '50',\n",
       " 'games',\n",
       " 'project',\n",
       " 'review',\n",
       " 'hand',\n",
       " 'email',\n",
       " 'near',\n",
       " 'below',\n",
       " 'men',\n",
       " 'wanted',\n",
       " '29',\n",
       " 'create',\n",
       " 'nothing',\n",
       " 'question',\n",
       " 'de',\n",
       " 'special',\n",
       " 'everyone',\n",
       " 'content',\n",
       " 'Posted',\n",
       " 'future',\n",
       " 'rather',\n",
       " 'check',\n",
       " 'taking',\n",
       " 'Thanks',\n",
       " 'works',\n",
       " 'From',\n",
       " 'month',\n",
       " 'front',\n",
       " 'law',\n",
       " 'space',\n",
       " 'news',\n",
       " 'Here',\n",
       " 'reason',\n",
       " 'add',\n",
       " 'isn',\n",
       " 'anyone',\n",
       " 'report',\n",
       " 'whether',\n",
       " 'major',\n",
       " 'main',\n",
       " 'young',\n",
       " 'development',\n",
       " 'North',\n",
       " 'event',\n",
       " '•',\n",
       " 'results',\n",
       " 'personal',\n",
       " 'especially',\n",
       " 'mean',\n",
       " 'issue',\n",
       " 'five',\n",
       " 'social',\n",
       " 'original',\n",
       " 'age',\n",
       " '....',\n",
       " 'born',\n",
       " 'taken',\n",
       " 'living',\n",
       " 'buy',\n",
       " 'd',\n",
       " 'll',\n",
       " 'Reply',\n",
       " 'reading',\n",
       " 'English',\n",
       " 'mind',\n",
       " 'study',\n",
       " 'building',\n",
       " 'result',\n",
       " 'type',\n",
       " 'looks',\n",
       " 'located',\n",
       " 'features',\n",
       " 'words',\n",
       " 'party',\n",
       " 'needed',\n",
       " 'size',\n",
       " 'plan',\n",
       " 'issues',\n",
       " 'else',\n",
       " 'search',\n",
       " 'black',\n",
       " 'version',\n",
       " 'News',\n",
       " 'included',\n",
       " 'Read',\n",
       " 'books',\n",
       " 'House',\n",
       " 'provided',\n",
       " 'Just',\n",
       " 'visit',\n",
       " 'couple',\n",
       " 'white',\n",
       " 'present',\n",
       " 'link',\n",
       " 'pay',\n",
       " 'coming',\n",
       " 'Some',\n",
       " 'face',\n",
       " 'kids',\n",
       " 'questions',\n",
       " 'friend',\n",
       " 'understand',\n",
       " 'however',\n",
       " 'human',\n",
       " 'became',\n",
       " 'ï',\n",
       " 'value',\n",
       " 'move',\n",
       " 'further',\n",
       " 'member',\n",
       " 'among',\n",
       " 'half',\n",
       " 'weeks',\n",
       " 'third',\n",
       " 'media',\n",
       " 'true',\n",
       " 'America',\n",
       " '»',\n",
       " 'soon',\n",
       " 'range',\n",
       " 'received',\n",
       " 'While',\n",
       " 'points',\n",
       " 'held',\n",
       " 'image',\n",
       " 'title',\n",
       " 'property',\n",
       " 'town',\n",
       " 'shows',\n",
       " 'offers',\n",
       " 'movie',\n",
       " 'happy',\n",
       " 'asked',\n",
       " 'outside',\n",
       " '£',\n",
       " 'various',\n",
       " 'writing',\n",
       " 'etc',\n",
       " 'class',\n",
       " '31',\n",
       " 'Is',\n",
       " 'contact',\n",
       " 'TV',\n",
       " 'upon',\n",
       " 'An',\n",
       " 'style',\n",
       " 'phone',\n",
       " 'stop',\n",
       " 'created',\n",
       " 'location',\n",
       " 'Click',\n",
       " 'wrote',\n",
       " 'running',\n",
       " 'art',\n",
       " 'low',\n",
       " 'child',\n",
       " 'heart',\n",
       " 'date',\n",
       " 'Do',\n",
       " 'matter',\n",
       " 'simple',\n",
       " 'address',\n",
       " 'played',\n",
       " 'similar',\n",
       " 'simply',\n",
       " 'office',\n",
       " 'enjoy',\n",
       " 'myself',\n",
       " 'saw',\n",
       " 'behind',\n",
       " 'complete',\n",
       " 'Center',\n",
       " 'card',\n",
       " 'death',\n",
       " 'problems',\n",
       " 'cannot',\n",
       " 'performance',\n",
       " 'Also',\n",
       " 'turn',\n",
       " 'action',\n",
       " 'learn',\n",
       " 'via',\n",
       " 'general',\n",
       " 'deal',\n",
       " 'includes',\n",
       " 'cost',\n",
       " 'bring',\n",
       " 'written',\n",
       " 'takes',\n",
       " 'window',\n",
       " 'Of',\n",
       " 'former',\n",
       " 'First',\n",
       " 'air',\n",
       " 'leave',\n",
       " 'likely',\n",
       " 'field',\n",
       " 'lost',\n",
       " 'areas',\n",
       " 'private',\n",
       " 'industry',\n",
       " 'store',\n",
       " 'usually',\n",
       " 'late',\n",
       " '2005',\n",
       " 'lead',\n",
       " 'Then',\n",
       " '40',\n",
       " 'clear',\n",
       " 'win',\n",
       " 'total',\n",
       " 'West',\n",
       " 'common',\n",
       " 'morning',\n",
       " 'Home',\n",
       " 'events',\n",
       " 'Day',\n",
       " 'released',\n",
       " 'Google',\n",
       " 'position',\n",
       " 'return',\n",
       " 'required',\n",
       " 'subject',\n",
       " 'account',\n",
       " 'ask',\n",
       " 'gets',\n",
       " 'comment',\n",
       " 'companies',\n",
       " 'provides',\n",
       " 'published',\n",
       " 'energy',\n",
       " 'currently',\n",
       " 'clean',\n",
       " 'President',\n",
       " 'instead',\n",
       " 'comments',\n",
       " 'final',\n",
       " 'longer',\n",
       " 'training',\n",
       " 'playing',\n",
       " '¯',\n",
       " 'period',\n",
       " 'interest',\n",
       " 'word',\n",
       " 'amount',\n",
       " 'source',\n",
       " 'rest',\n",
       " 'record',\n",
       " 'worked',\n",
       " 'Great',\n",
       " 'model',\n",
       " 'addition',\n",
       " 'technology',\n",
       " 'wasn',\n",
       " '<',\n",
       " 'web',\n",
       " 'details',\n",
       " 'role',\n",
       " 'College',\n",
       " 'goes',\n",
       " 'Well',\n",
       " 'Park',\n",
       " 'Free',\n",
       " 'began',\n",
       " 'professional',\n",
       " 'changes',\n",
       " 'strong',\n",
       " 'meet',\n",
       " 'watch',\n",
       " 'hotel',\n",
       " 'certain',\n",
       " 'saying',\n",
       " 'sense',\n",
       " 'forward',\n",
       " 'gave',\n",
       " 'color',\n",
       " 'recently',\n",
       " 'inside',\n",
       " 'wrong',\n",
       " 'album',\n",
       " 'staff',\n",
       " 'designed',\n",
       " 'paper',\n",
       " 'amazing',\n",
       " 'drive',\n",
       " 'woman',\n",
       " 'hit',\n",
       " 'user',\n",
       " 'rights',\n",
       " 'decided',\n",
       " 'recent',\n",
       " 'key',\n",
       " 'continue',\n",
       " 'rate',\n",
       " 'posted',\n",
       " 'itself',\n",
       " 'code',\n",
       " 'favorite',\n",
       " 'seem',\n",
       " 'International',\n",
       " 'political',\n",
       " 'View',\n",
       " 'Thank',\n",
       " 'maybe',\n",
       " 'percent',\n",
       " 'remember',\n",
       " 'Why',\n",
       " '~',\n",
       " 'London',\n",
       " 'test',\n",
       " 'stuff',\n",
       " 'write',\n",
       " 'computer',\n",
       " 'cause',\n",
       " 'cut',\n",
       " 'according',\n",
       " 'built',\n",
       " 'player',\n",
       " 'popular',\n",
       " 'High',\n",
       " 'Most',\n",
       " '01',\n",
       " 'management',\n",
       " 'interesting',\n",
       " 'son',\n",
       " 'ways',\n",
       " 'education',\n",
       " 'sound',\n",
       " 'summer',\n",
       " 'ready',\n",
       " 'natural',\n",
       " 'national',\n",
       " 'software',\n",
       " '·',\n",
       " 'David',\n",
       " 'tried',\n",
       " 'yourself',\n",
       " 'players',\n",
       " 'hot',\n",
       " 'higher',\n",
       " 'policy',\n",
       " 'related',\n",
       " 'Don',\n",
       " 'miles',\n",
       " 'entire',\n",
       " 'specific',\n",
       " 'wonderful',\n",
       " 'Yes',\n",
       " 'felt',\n",
       " 'section',\n",
       " 'British',\n",
       " 'thinking',\n",
       " 'x',\n",
       " 'release',\n",
       " 'song',\n",
       " 'San',\n",
       " 'six',\n",
       " 'heard',\n",
       " 'particular',\n",
       " 'users',\n",
       " 'War',\n",
       " 'average',\n",
       " 'hear',\n",
       " 'Best',\n",
       " 'themselves',\n",
       " 'security',\n",
       " 'file',\n",
       " 'https',\n",
       " 'ones',\n",
       " '05',\n",
       " 'oil',\n",
       " 'Dr.',\n",
       " 'Facebook',\n",
       " 'See',\n",
       " 'California',\n",
       " 'cover',\n",
       " 'allow',\n",
       " 'center',\n",
       " 'Friday',\n",
       " 'terms',\n",
       " 'road',\n",
       " 'receive',\n",
       " 'board',\n",
       " 'war',\n",
       " 'material',\n",
       " 'wife',\n",
       " 'lives',\n",
       " 'sometimes',\n",
       " 'parts',\n",
       " 'UK',\n",
       " 'individual',\n",
       " 'chance',\n",
       " 'Health',\n",
       " 'items',\n",
       " 'answer',\n",
       " 'girl',\n",
       " 'himself',\n",
       " 'India',\n",
       " 'Street',\n",
       " 'walk',\n",
       " 'definitely',\n",
       " 'C',\n",
       " 'production',\n",
       " 'worth',\n",
       " 'systems',\n",
       " 'character',\n",
       " 'throughout',\n",
       " 'reviews',\n",
       " 'giving',\n",
       " 'career',\n",
       " 'increase',\n",
       " 'unique',\n",
       " 'mother',\n",
       " 'completely',\n",
       " 'picture',\n",
       " 'although',\n",
       " 'St.',\n",
       " 'additional',\n",
       " 'customers',\n",
       " 'sex',\n",
       " 'choose',\n",
       " 'parents',\n",
       " '09',\n",
       " 'involved',\n",
       " 'medical',\n",
       " 'follow',\n",
       " 'piece',\n",
       " 'articles',\n",
       " 'red',\n",
       " 'Washington',\n",
       " 'band',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hula\n"
     ]
    }
   ],
   "source": [
    "word = \"hoop\"\n",
    "\n",
    "count = 0\n",
    "while (word.lower() in model.get_nearest_neighbors(word)[count][1].lower()):\n",
    "    count += 1\n",
    "print(model.get_nearest_neighbors(word)[count][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('theorizes', 0.8441917896270752), ('posits', 0.7550536394119263), ('hypothesises', 0.7534146308898926), ('speculates', 0.7471299171447754), ('hypothesized', 0.6967670917510986), ('theorized', 0.6850240230560303), ('hypothesize', 0.6797716021537781), ('suggests', 0.6776619553565979), ('surmises', 0.6726735830307007), ('argues', 0.6641719341278076)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['hypothesizes'],topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hypothesizes', 0.755053699016571), ('theorizes', 0.7324862480163574), ('posit', 0.6966612339019775), ('posited', 0.6854887008666992), ('asserts', 0.6767232418060303), ('argues', 0.6661661267280579), ('contends', 0.6580398082733154), ('supposes', 0.6341761350631714), ('postulates', 0.6297484040260315), ('theorises', 0.6291747689247131)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['posits'],topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('explicates', 0.7070539593696594), ('delineates', 0.6947036385536194), ('expresses', 0.6647325158119202), ('articulating', 0.6598384380340576), ('elucidates', 0.6513511538505554), ('enunciates', 0.6481024622917175), ('embodies', 0.647651731967926), ('Articulates', 0.6450914740562439), ('exemplifies', 0.6378193497657776), ('contextualizes', 0.6367567777633667)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['articulates'],topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dance', 0.8184520602226257), ('dancing', 0.7757260203361511), ('danced', 0.6930131912231445), ('dancers', 0.6854677796363831), ('dancings', 0.6833518743515015), ('dances.', 0.66910320520401), ('dancing.The', 0.6400177478790283), ('dance.The', 0.6386830806732178), ('waltzes', 0.6372228264808655), ('folk-dance', 0.63532954454422)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['dances'],topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('interact', 0.7526844143867493), ('communicates', 0.6893189549446106), ('interacting', 0.6508557200431824), ('behaves', 0.6094906330108643), ('reacts', 0.6036487221717834), ('interacted', 0.5847289562225342), ('manipulates', 0.5778606534004211), ('engages', 0.5703780055046082), ('mediates', 0.5667899250984192), ('collaborates', 0.563274085521698)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['interacts'],topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apartments', 0.7412919998168945), ('aparment', 0.7349161505699158), ('appartment', 0.7225771546363831), ('apartment.The', 0.7040624618530273), ('Apartment', 0.6907716393470764), ('aprtment', 0.687786340713501), ('apartmen', 0.6844730377197266), ('apartment.This', 0.6818587779998779), ('apt.', 0.6804991364479065), ('apartment.', 0.6682141423225403), ('condo', 0.6641570329666138), ('apartment.It', 0.6640224456787109), ('penthouse', 0.6630098819732666), ('apartement', 0.6616573333740234), ('one-bedroom', 0.6616435050964355), ('house', 0.6541084051132202), ('apartment-', 0.6465580463409424), ('apartment.In', 0.6436839699745178), ('townhouse', 0.6428278684616089), ('aparments', 0.6426208019256592), ('apartme', 0.6296799182891846), ('apartmet', 0.625112771987915), ('apatment', 0.6221145987510681), ('apartment.I', 0.6201617121696472), ('apartements', 0.6181816458702087), ('apartments.The', 0.6151202917098999), ('apartment-house', 0.6098417043685913), ('two-bedroom', 0.6088148951530457), ('2-bedroom', 0.6071880459785461), ('apartment.A', 0.6059398055076599), ('apartment.When', 0.6055129170417786), ('studio-apartment', 0.6008527278900146), ('bedroom', 0.6008481979370117), ('apratment', 0.5971068739891052), ('apartament', 0.5968698859214783), ('apartment-hotel', 0.5933474898338318), ('apartmentThis', 0.5932570099830627), ('apartm', 0.5930550694465637), ('apartment--', 0.5920145511627197), ('mini-apartment', 0.5855963230133057)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.most_similar(positive=['apartment'],topn=40)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8b5e87e922a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "word = \"stroll\"\n",
    "count = 0\n",
    "while True:\n",
    "    if word.lower()[0:2] in model.most_similar(positive=[word.lower()],topn=20)[count][1]:\n",
    "        count += 1\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "print(count)\n",
    "print(model2.get_nearest_neighbors(word.lower(), 20)[count][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gensim.models' has no attribute 'load_word2vec_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9c2f989832df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/alex/result/GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#similar = model.most_similar(positive=['king', 'woman'],negative=['man'],topn=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gensim.models' has no attribute 'load_word2vec_format'"
     ]
    }
   ],
   "source": [
    "# RUN ONCE\n",
    "#\n",
    "#\n",
    "#\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/alex/result/GoogleNews-vectors-negative300.bin')\n",
    "#similar = model.most_similar(positive=['king', 'woman'],negative=['man'],topn=10)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "#\"/Users/alex/result/GoogleNews-vectors-negative300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
