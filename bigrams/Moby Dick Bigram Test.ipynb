{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is from the below link\n",
    "# https://www.geeksforgeeks.org/tf-idf-for-bigrams-trigrams/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the file \n",
    "txt1 = []\n",
    "with open('/Users/alex/Desktop/Writing + AI/moby-dick.txt') as file:\n",
    "    txt1 = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenberg eBook of Moby-Dick, by Herman Melville\\n',\n",
       " '\\n',\n",
       " 'This eBook is for the use of anyone anywhere in the United States and\\n',\n",
       " 'most other parts of the world at no cost and with almost no restrictions\\n',\n",
       " 'whatsoever. You may copy it, give it away or re-use it under the terms\\n',\n",
       " 'of the Project Gutenberg License included with this eBook or online at\\n',\n",
       " 'www.gutenberg.org. If you are not located in the United States, you\\n',\n",
       " 'will have to check the laws of the country where you are located before\\n',\n",
       " 'using this eBook.\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def remove_string_special_characters(s):\n",
    "      \n",
    "    # removes special characters with ' '\n",
    "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
    "    stripped = re.sub('_', '', stripped)\n",
    "      \n",
    "    # Change any white space to one space\n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "      \n",
    "    # Remove start and end white spaces\n",
    "    stripped = stripped.strip()\n",
    "    if stripped != '':\n",
    "            return stripped.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(txt1)):\n",
    "    txt1[i] = remove_string_special_characters(txt1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenberg ebook mobydick herman melville',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever you may copy it give it away or reuse it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at',\n",
       " 'wwwgutenbergorg if you are not located in the united states you',\n",
       " 'will have to check the laws of the country where you are located before',\n",
       " 'using this ebook',\n",
       " 'title mobydick',\n",
       " 'author herman melville']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(txt1) - 1, -1, -1):\n",
    "    if txt1[i] == None:\n",
    "        del txt1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in txt1:\n",
    "    if i == None:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword removal : FUTURE\n",
    "stop_words = set(stopwords.words('english'))\n",
    "your_list = [\"whale\", \"gutenberg\", \"gutenbergtm\", \"project\"]\n",
    "for i, line in enumerate(txt1):\n",
    "    txt1[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x not in stop_words) and (x not in your_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X1 : \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Getting bigrams \n",
    "vectorizer = CountVectorizer(ngram_range =(2, 2))\n",
    "X1 = vectorizer.fit_transform(txt1) \n",
    "features = (vectorizer.get_feature_names())\n",
    "print(\"\\n\\nX1 : \\n\", X1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Applying TFIDF\n",
    "# You can still get n-grams here\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 2))\n",
    "X2 = vectorizer.fit_transform(txt1)\n",
    "scores = (X2.toarray())\n",
    "print(\"\\n\\nScores : \\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                      term       rank\n",
      "43656           moby dick  21.671202\n",
      "9177         captain ahab  18.206184\n",
      "47522             old man  16.416281\n",
      "64623        sperm whales  14.755460\n",
      "14237          cried ahab   9.595589\n",
      "9263        captain peleg   8.422896\n",
      "4117              aye aye   8.323520\n",
      "47851            one hand   8.217665\n",
      "19004    electronic works   7.853372\n",
      "78336         whales head   7.744639\n",
      "37574              let us   7.670104\n",
      "39720             look ye   7.294971\n",
      "17730           dont know   7.219265\n",
      "48046            one side   7.158692\n",
      "20642           every one   7.010812\n",
      "3064   archive foundation   6.927531\n",
      "44413         mr starbuck   6.776805\n",
      "14284         cried stubb   6.269868\n",
      "74529       united states   6.247110\n",
      "18516             dye see   5.983007\n",
      "14279      cried starbuck   5.923764\n",
      "81538               ye ye   5.768464\n",
      "45880         new bedford   5.750486\n",
      "57305          said stubb   5.646087\n",
      "70630            thou art   5.610723\n",
      "47526            old mans   5.562873\n",
      "63521      something like   5.514437\n",
      "50084        pequod meets   5.431468\n",
      "34593           ivory leg   5.425445\n",
      "77858          well known   5.423419\n",
      "81576           years ago   5.344420\n",
      "9130            cape horn   5.335632\n",
      "80914          would seem   5.332343\n",
      "78600      whaling voyage   5.217224\n",
      "82076           young man   5.196649\n",
      "45780          never mind   5.166838\n",
      "81466              ye see   5.056692\n",
      "38839    literary archive   5.032027\n",
      "71553            thus far   5.011320\n",
      "40116           lower jaw   5.009684\n",
      "71274          three four   4.875737\n",
      "19003     electronic work   4.824149\n",
      "71358         three years   4.765458\n",
      "17826           dost thou   4.664444\n",
      "19979            ere long   4.636400\n",
      "56745         round round   4.590451\n",
      "60108           set forth   4.489552\n",
      "67166         stubb flask   4.437980\n",
      "1672         almost every   4.432037\n",
      "44492           much like   4.382036\n"
     ]
    }
   ],
   "source": [
    "# Getting top ranking features\n",
    "sums = X2.sum(axis = 0)\n",
    "data1 = []\n",
    "for col, term in enumerate(features):\n",
    "    data1.append( (term, sums[0, col] ))\n",
    "ranking = pd.DataFrame(data1, columns = ['term', 'rank'])\n",
    "words = (ranking.sort_values('rank', ascending = False))\n",
    "print (\"\\n\\nWords : \\n\", words.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
